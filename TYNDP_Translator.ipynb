{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TYNDP Translator\n",
    "\n",
    "Converts TYNDP data into the LEGO format. The TYNDP models future power grid requirements by representing bidding zones and their respective transport capacities.\n",
    "\n",
    "Figure 1 provides an overview of the bidding zone names.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"assets/Bidding_Zones.png\" alt=\"ENTSOE Bidding Zones\" width=\"500\"/>\n",
    "    <figcaption>Figure 1: Bidding Zones according to ENTSO-E.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths\n",
    "import os\n",
    "\n",
    "# Simulation year (2030, 2040, 2050)\n",
    "simulation_year = 2030\n",
    "\n",
    "Datasource = 'TYNDP2024'  # Raw Data source\n",
    "\n",
    "# Scenario (National Trends, Distributed Energy, Global Ambition)\n",
    "scenario = 'Distributed Energy' \n",
    "\n",
    "# Climate year (1982-2019). The three years by TYNDP2024: 1995, 2008, 2009. Standard: 2009\n",
    "cy_year = 2009\n",
    "\n",
    "# Path to TYNDP input data (Backup Available at Institutsdaten\\Daten\\TYNDP2024)\n",
    "tyndp_dir = 'L:\\TYNDP 24\\Data'\n",
    "\n",
    "# Path to template LEGO files (by default stored with script on GitHub)\n",
    "template_dir = 'L:\\TYNDP 24\\TYNDP Translator\\LEGO_data_templates_Pyomo'\n",
    "\n",
    "# Path to pypsa data for electric line parameters\n",
    "pypsa_dir = 'PyPSA_Data'\n",
    "\n",
    "\n",
    "# Define destination folder where the results should be stored\n",
    "if simulation_year == 2030:\n",
    "    if scenario == 'National Trends':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2030_NT'\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2030_DE'\n",
    "    elif scenario == 'Global Ambition':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2030_GA'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2040:\n",
    "    if scenario == 'National Trends':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2040_NT'\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2040_DE'\n",
    "    elif scenario == 'Global Ambition':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2040_GA'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2050:\n",
    "    if scenario == 'National Trends':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2050_NT'\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2050_DE'\n",
    "    elif scenario == 'Global Ambition':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\Pyomo\\V2G_2050_GA'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "\n",
    "\n",
    "## Other parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Pre-Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from copy import copy\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the destination directory exists\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "else:\n",
    "    print(\"Warning: Destination directory already exists. Files may be overwritten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check if a file is currently open\n",
    "def is_file_open(destination_file):\n",
    "    \"\"\"Check if a file is open by another application.\"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        try:\n",
    "            with open(destination_file, 'r+b') as file:\n",
    "                pass  # If successful, file is not open elsewhere\n",
    "            return False\n",
    "        except PermissionError:\n",
    "            return True\n",
    "    else:  # macOS/Linux\n",
    "        temp_file = os.path.join(os.path.dirname(destination_file), '~$' + os.path.basename(destination_file))\n",
    "        if os.path.exists(temp_file):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Copying files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Power_Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for source data, template, and destination\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_parameters = os.path.join(template_dir, 'Power_Parameters.xlsx')\n",
    "destination_file_parameters = os.path.join(destination_dir, 'Power_Parameters.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_parameters):\n",
    "    if is_file_open(destination_file_parameters):\n",
    "        sys.exit(f\"File '{destination_file_parameters}' is currently open by another application.\")\n",
    "    os.remove(destination_file_parameters)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_parameters, destination_file_parameters)\n",
    "\n",
    "# Load relevant data from the source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Parameters\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Open the destination workbook and select the active worksheet\n",
    "destination_wb = load_workbook(destination_file_parameters)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Update specific cells in the destination file with values from the source data\n",
    "destination_ws.cell(row=5, column=3, value=df_other_sources.iloc[2,1])\n",
    "destination_ws.cell(row=56, column=3, value=df_other_sources.iloc[3,1])\n",
    "\n",
    "# Save and close the updated file\n",
    "destination_wb.save(destination_file_parameters)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"File saved successfully at: {destination_file_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Power_BusInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for source data, template, and destination\n",
    "source_file_businfo = os.path.join(tyndp_dir, 'Nodes/LIST OF NODES.xlsx')\n",
    "source_file_businfo_offshore = os.path.join(tyndp_dir, 'Line data/ReferenceGrid_Electricity.xlsx')\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_businfo = os.path.join(template_dir, 'Power_BusInfo.xlsx')\n",
    "destination_file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_businfo):\n",
    "    if is_file_open(destination_file_businfo):\n",
    "        sys.exit(f\"File '{destination_file_businfo}' is currently open by another application.\")\n",
    "    os.remove(destination_file_businfo)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_businfo, destination_file_businfo)\n",
    "\n",
    "# Load the destination workbook and select the first sheet\n",
    "destination_wb = load_workbook(destination_file_businfo)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Load and process (onshore) bus data\n",
    "df_source = pd.read_excel(source_file_businfo, usecols=[0], header=0)  # Read column A (bus names)\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_BusInfo\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Write onshore buses to the destination file, starting at row 8 in column C\n",
    "start_row = 8\n",
    "for i, value in enumerate(df_source.iloc[:, 0], start=start_row):\n",
    "    destination_ws[f'C{i}'] = value # Bus name\n",
    "    destination_ws[f'D{i}'] = f'Zon_{value}' # Zone name\n",
    "\n",
    "    # Assign static parameter values from df_other_sources\n",
    "    destination_ws[f'E{i}'] = df_other_sources.iloc[4, 1] # BasVolt\n",
    "    destination_ws[f'F{i}'] = df_other_sources.iloc[5, 1] # maxVolt\n",
    "    destination_ws[f'G{i}'] = df_other_sources.iloc[6, 1] # minVolt\n",
    "    destination_ws[f'H{i}'] = df_other_sources.iloc[7, 1] # Bs\n",
    "    destination_ws[f'I{i}'] = df_other_sources.iloc[8, 1] # Gs\n",
    "    destination_ws[f'J{i}'] = df_other_sources.iloc[9, 1] # PowerFactor\n",
    "    if df_other_sources.iloc[10, 1] != \"\":\n",
    "        destination_ws[f'K{i}'] = df_other_sources.iloc[10, 1] # YearCom\n",
    "    if df_other_sources.iloc[11, 1] != \"\":\n",
    "        destination_ws[f'L{i}'] = df_other_sources.iloc[11, 1] # YearDecom\n",
    "    if df_other_sources.iloc[12, 1] != \"\":\n",
    "        destination_ws[f'M{i}'] = df_other_sources.iloc[12, 1] # lat\n",
    "    if df_other_sources.iloc[13, 1] != \"\":\n",
    "        destination_ws[f'N{i}'] = df_other_sources.iloc[12, 1] # lon\n",
    "    destination_ws[f'O{i}'] = 1 # Whether node is relevant for end result (1) or not (0)\n",
    "    destination_ws[f'P{i}'] = f\"V2G_{simulation_year}_{scenario}\" # Which package this belongs to\n",
    "    destination_ws[f'Q{i}'] = Datasource # Where the data for the entry comes from\n",
    "\n",
    "\n",
    "\n",
    "# Load and process offshore bus data\n",
    "df_source_offshore = pd.read_excel(source_file_businfo_offshore, sheet_name=\"Offshore (for info)\", usecols=[0], header=0)\n",
    "\n",
    "# Extract offshore bus names and split ranges (e.g., \"AL00-BA00\" â†’ \"AL00\", \"BA00\")\n",
    "bus_list = []\n",
    "for entry in df_source_offshore.iloc[:, 0].dropna().astype(str):\n",
    "    bus_list.extend(entry.split('-'))\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "bus_list = list(dict.fromkeys(bus_list))\n",
    "\n",
    "# Get the list of existing onshore buses\n",
    "existing_buses = set(df_source.iloc[:, 0].dropna())\n",
    "\n",
    "# Identify offshore buses that are not already in column B\n",
    "new_buses = [bus for bus in bus_list if bus not in existing_buses]   \n",
    "\n",
    "# Append new offshore buses to the destination file\n",
    "if new_buses:\n",
    "    for i, value in enumerate(new_buses, start=len(existing_buses) + start_row):\n",
    "        destination_ws[f'C{i}'] = value # Bus name\n",
    "        destination_ws[f'D{i}'] = f'Zon_{value}' # Zone name\n",
    "\n",
    "        # Assign static parameter values from df_other_sources\n",
    "        destination_ws[f'E{i}'] = df_other_sources.iloc[4, 1] # BasVolt\n",
    "        destination_ws[f'F{i}'] = df_other_sources.iloc[5, 1] # maxVolt\n",
    "        destination_ws[f'G{i}'] = df_other_sources.iloc[6, 1] # minVolt\n",
    "        destination_ws[f'H{i}'] = df_other_sources.iloc[7, 1] # Bs\n",
    "        destination_ws[f'I{i}'] = df_other_sources.iloc[8, 1] # Gs\n",
    "        destination_ws[f'J{i}'] = df_other_sources.iloc[9, 1] # PowerFactor\n",
    "        if df_other_sources.iloc[10, 1] != \"\":\n",
    "            destination_ws[f'K{i}'] = df_other_sources.iloc[10, 1] # YearCom\n",
    "        if df_other_sources.iloc[11, 1] != \"\":\n",
    "            destination_ws[f'L{i}'] = df_other_sources.iloc[11, 1] # YearDecom\n",
    "        if df_other_sources.iloc[12, 1] != \"\":\n",
    "            destination_ws[f'M{i}'] = df_other_sources.iloc[12, 1] # lat\n",
    "        if df_other_sources.iloc[13, 1] != \"\":\n",
    "            destination_ws[f'N{i}'] = df_other_sources.iloc[12, 1] # lon\n",
    "        destination_ws[f'O{i}'] = \"1\" # Whether node is relevant for end result (1) or not (0)\n",
    "        destination_ws[f'P{i}'] = f\"V2G_{simulation_year}_{scenario}\" # Which package this belongs to\n",
    "        destination_ws[f'Q{i}'] = Datasource # Where the data for the entry comes from\n",
    "\n",
    "# Save and close the updated destination file\n",
    "destination_wb.save(destination_file_businfo)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"File saved successfully at: {destination_file_businfo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Power_Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for source data, template, and destination\n",
    "if simulation_year == 2030:\n",
    "    if scenario == 'National Trends':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/NT/Electricity demand profiles/2030_National Trends.xlsx')\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/DE/2030/ELECTRICITY_MARKET DE 2030.xlsx')\n",
    "    elif scenario == 'Global Ambition':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/GA/2030/ELECTRICITY_MARKET GA 2030.xlsx')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2040:\n",
    "    if scenario == 'National Trends':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/NT/Electricity demand profiles/2040_National Trends.xlsx')\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/DE/2040/ELECTRICITY_MARKET DE 2040.xlsx')\n",
    "    elif scenario == 'Global Ambition':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/GA/2030/ELECTRICITY_MARKET GA 2040.xlsx')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2050:\n",
    "    if scenario == 'National Trends':\n",
    "        raise ValueError(\"National Trends scenario is not available for 2050.\")\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/DE/2050/ELECTRICITY_MARKET DE 2050.xlsx')\n",
    "    elif scenario == 'Global Ambition':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/GA/2050/ELECTRICITY_MARKET GA 2050.xlsx')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_demand = os.path.join(template_dir, 'Power_Demand.xlsx')\n",
    "destination_file_demand = os.path.join(destination_dir, 'Power_Demand.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_demand):\n",
    "    if is_file_open(destination_file_demand):\n",
    "        sys.exit(f\"File '{destination_file_demand}' is currently open by another application.\")\n",
    "    os.remove(destination_file_demand)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_demand, destination_file_demand)\n",
    "\n",
    "# Validate that the selected year is within the supported range\n",
    "if cy_year < 1982 or cy_year > 2019:\n",
    "    raise ValueError(\"Year must be between 1982 and 2019.\")\n",
    "\n",
    "# Load the demand profiles Excel file (containing multiple sheets for different nodes)\n",
    "demand_profiles_wb = pd.ExcelFile(source_file_demand_profiles)\n",
    "\n",
    "# Load additional parameters from another source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Demand\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Load the destination workbook where the data will be written\n",
    "destination_wb = load_workbook(destination_file_demand)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Define the starting row in the destination file for writing demand profiles\n",
    "row_start = 8\n",
    "\n",
    "# Process each worksheet (node) in the demand profiles file\n",
    "for sheet_name in demand_profiles_wb.sheet_names:\n",
    "    print(f\"Start copying demand for {sheet_name}.\")\n",
    "    \n",
    "    # Load the time-series data for the node, skipping metadata rows\n",
    "    node_df = demand_profiles_wb.parse(sheet_name, skiprows=11, nrows=8760)\n",
    "\n",
    "    # Identify year columns (assuming data for 1982-2019 starts from column E)\n",
    "    year_columns = node_df.columns[4:len(node_df.columns)]\n",
    "    \n",
    "    # Check if the selected year is available in the dataset\n",
    "    if cy_year not in year_columns:\n",
    "        print(f\"Year {cy_year} not found in sheet {sheet_name}. Skipping node.\")\n",
    "        continue\n",
    "    \n",
    "    # Get the column index corresponding to the selected year\n",
    "    year_col_idx = year_columns.get_loc(cy_year) + 4  # Convert relative index to absolute column index\n",
    "\n",
    "    # Extract the hourly demand time series for the selected year\n",
    "    time_series = node_df.iloc[:, year_col_idx]\n",
    "\n",
    "    # Write periode and node name value to the destination file\n",
    "\n",
    "    destination_ws[f'C{row_start}'] = df_other_sources.iloc[2, 1] # Periode\n",
    "    destination_ws[f'D{row_start}'] = sheet_name # Node name\n",
    "    destination_ws[f'E{i}'] = f\"V2G_{simulation_year}_{scenario}\" # Which package this belongs to\n",
    "    destination_ws[f'F{i}'] = Datasource # Where the data for the entry comes from\n",
    "    # Write the demand values (8760 hours) into the corresponding row, starting from column E\n",
    "    for i, demand in enumerate(time_series, start=7):\n",
    "        destination_ws.cell(row=row_start, column=i, value=round(demand,2))\n",
    "    \n",
    "    # Move to the next row for the next node\n",
    "    row_start += 1\n",
    "\n",
    "# Save and close the modified workbook to the destination file\n",
    "destination_wb.save(destination_file_demand)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_demand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Power_Inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for source data, template, and destination\n",
    "if simulation_year == 2030:\n",
    "    folder_source_files_inflows = os.path.join(tyndp_dir, 'Hydro Inflows/2030')\n",
    "elif simulation_year == 2040:\n",
    "    folder_source_files_inflows = os.path.join(tyndp_dir, 'Hydro Inflows/2040')\n",
    "elif simulation_year == 2050:\n",
    "    folder_source_files_inflows = os.path.join(tyndp_dir, 'Hydro Inflows/2050')\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_inflows = os.path.join(template_dir, 'Power_Inflows.xlsx')\n",
    "destination_file_inflows = os.path.join(destination_dir, 'Power_Inflows.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_inflows):\n",
    "    if is_file_open(destination_file_inflows):\n",
    "        sys.exit(f\"File '{destination_file_inflows}' is currently open by another application.\")\n",
    "    os.remove(destination_file_inflows)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_inflows, destination_file_inflows)\n",
    "\n",
    "# Load additional parameters from another source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Inflows\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Load the destination workbook where the processed data will be stored\n",
    "destination_wb = load_workbook(destination_file_inflows)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Retrieve all relevant inflow data files from the specified folder\n",
    "inflows_files = sorted(f for f in os.listdir(folder_source_files_inflows) if (f.startswith(\"PEMMDB\") and f.endswith(\".xlsx\")))\n",
    "\n",
    "# Define the starting row in the destination file for writing network data\n",
    "row_start = 7\n",
    "\n",
    "# Process each inflow file\n",
    "for filename in inflows_files:\n",
    "    file_path = os.path.join(folder_source_files_inflows, filename)  # Construct full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a file\n",
    "\n",
    "        # Load the inflows Excel file\n",
    "        inflows_wb = pd.ExcelFile(file_path)\n",
    "        print(file_path)\n",
    "\n",
    "        # Load different types of inflow data from the workbook\n",
    "        ror_df = inflows_wb.parse('Run of River - Year Dependent', skiprows=1, nrows=365)\n",
    "        pondage_df = inflows_wb.parse('Pondage - Year Dependent', skiprows=1, nrows=365)\n",
    "        hs_df = inflows_wb.parse('Reservoir - Year Dependent', skiprows=1, nrows=53)\n",
    "        hps_df = inflows_wb.parse('PS Open - Year Dependent', skiprows=1, nrows=53)\n",
    "        hcps_df = inflows_wb.parse('PS Closed - Year Dependent', skiprows=1, nrows=53)\n",
    "\n",
    "        # Identify year columns (assuming data for 1982-2019 starts from column D)\n",
    "        year_columns = ror_df.columns[3:]\n",
    "        \n",
    "        # Check if the selected year is available in the dataset\n",
    "        if cy_year not in year_columns:\n",
    "            print(f\"Year {cy_year} not found in sheet {filename}. Skipping node.\")\n",
    "            continue\n",
    "\n",
    "        # Get the column index corresponding to the selected year\n",
    "        year_col_idx = year_columns.get_loc(cy_year) + 3  # Adjust index to match actual column position\n",
    "\n",
    "        # Extract the inflow time series for the selected year, replacing NaNs with zeros\n",
    "        time_series_ror = ror_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_pondage = pondage_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_hs = hs_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_hps = hps_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_hcps = hcps_df.iloc[:, year_col_idx].fillna(0)\n",
    "\n",
    "        # Combine Run-of-River (ROR) and Pondage inflow data\n",
    "        time_series_ror_pondage = time_series_ror + time_series_pondage\n",
    "\n",
    "        # Define inflow categories and their respective time series\n",
    "        inflow_categories = {\n",
    "            'ROR': time_series_ror_pondage,\n",
    "            'HS': time_series_hs,\n",
    "            'HPS': time_series_hps,\n",
    "            'HCPS': time_series_hcps\n",
    "        }\n",
    "\n",
    "        # Process and write data for each inflow category\n",
    "        for inflow_type, series in inflow_categories.items():\n",
    "            if series.sum() == 0:  # Skip writing if the entire time series is zero\n",
    "                continue\n",
    "\n",
    "            # Write periode and power plant name value to the destination file\n",
    "            destination_ws[f'B{row_start}'] = df_other_sources.iloc[2, 1] # Periode\n",
    "            destination_ws[f'C{row_start}'] = filename.split('_')[1] + inflow_type # Power plant name\n",
    "            print(f\"Writing {inflow_type} data...\")\n",
    "\n",
    "            # Define the starting column in the destination file for writing inflows\n",
    "            column_start = 4\n",
    "\n",
    "            # RoR inflows are provided as a daily profile\n",
    "            if inflow_type == 'ROR':\n",
    "                # Distribute daily inflows evenly across 24 hours\n",
    "                for inflow in series:  \n",
    "                    for h in range(24):  # Repeat for each hour of the day\n",
    "                        destination_ws.cell(row=row_start, column=column_start, value=round(inflow*1000 / 24,4))\n",
    "                        column_start += 1\n",
    "            \n",
    "            # HS, HPS and HS inflows are provided as weekly profiles\n",
    "            elif inflow_type in ['HS', 'HPS', 'HCPS']:\n",
    "                hour_count = 0  # Counter to track written hours\n",
    "                previous_inflow = 0 # Store previous week's inflow value\n",
    "                \n",
    "                for inflow in series:\n",
    "                    for h in range(7 * 24):  # Distribute weekly inflows across 7 days (168 hours)\n",
    "                        if hour_count >= 8760:  # Stop once reaching 8760 hours\n",
    "                            break\n",
    "\n",
    "                        # If in the last week and inflow is missing, use previous week's value\n",
    "                        if hour_count >= 8736 and inflow == 0:\n",
    "                            inflow = previous_inflow if previous_inflow is not None else 0\n",
    "                        \n",
    "                        # Write the inflow value to the corresponding cell\n",
    "                        destination_ws.cell(row=row_start, column=column_start, value=round(inflow*1000 / (7 * 24),4))\n",
    "                        \n",
    "                        previous_inflow = inflow # Store current inflow as reference for next iteration\n",
    "                        column_start += 1\n",
    "                        hour_count += 1\n",
    "\n",
    "                    if hour_count >= 8760:  # Stop processing once 8760 hours are written\n",
    "                        break\n",
    "        \n",
    "            # Move to the next row for the next inflow category\n",
    "            row_start += 1\n",
    "\n",
    "# Save and close the modified workbook to the destination file\n",
    "destination_wb.save(destination_file_inflows)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_inflows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Power_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for source data, template, and destination file\n",
    "source_file_network = os.path.join(tyndp_dir, 'Line data/ReferenceGrid_Electricity.xlsx')\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_network = os.path.join(template_dir, 'Power_Network.xlsx')\n",
    "destination_file_network = os.path.join(destination_dir, 'Power_Network.xlsx')\n",
    "\n",
    "# If the destination file exists, remove it to ensure a clean start\n",
    "if os.path.exists(destination_file_network):\n",
    "    if is_file_open(destination_file_network):\n",
    "        sys.exit(f\"File '{destination_file_network}' is currently open by another application.\")\n",
    "    os.remove(destination_file_network)\n",
    "\n",
    "# Copy the template file to the destination for modification\n",
    "shutil.copy(template_file_network, destination_file_network)\n",
    "\n",
    "# Load the destination workbook and select the active worksheet\n",
    "destination_wb = load_workbook(destination_file_network)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Load onshore transmission network data\n",
    "df_source = pd.read_excel(source_file_network, usecols=[0,1,2], header=0, sheet_name=\"2030\")  # Read column A\n",
    "\n",
    "# Load additional parameters from another source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Network\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Replace column 1 values with the maximum of column 1 and column 2 to get the max transport capacity\n",
    "df_source.iloc[:, 1] = df_source.iloc[:, 1].combine(df_source.iloc[:, 2], max)\n",
    "\n",
    "# Remove column C as it's no longer needed\n",
    "df_source.drop(df_source.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Keep only rows where the transmission capacity (column B) is non-zero\n",
    "df_source = df_source[df_source.iloc[:, 1] != 0]\n",
    "\n",
    "# Define the starting row in the destination file for writing NTC data\n",
    "start_row = 8\n",
    "\n",
    "# Write processed onshore network data to the destination file\n",
    "for i, value in enumerate(df_source.iloc[:, 0], start=start_row):\n",
    "    destination_ws[f'C{i}'] = value.split('-')[0]  # Bus from name in column B\n",
    "    destination_ws[f'D{i}'] = value.split('-')[1]  # Bus to name in column C\n",
    "\n",
    "    # Assign predefined static values from the other sources file\n",
    "    destination_ws[f'E{i}'] = df_other_sources.iloc[4, 1] # Circuit\n",
    "    destination_ws[f'I{i}'] = df_other_sources.iloc[9, 1] # TapAngle\n",
    "    destination_ws[f'J{i}'] = df_other_sources.iloc[10, 1] # TapRatio\n",
    "    destination_ws[f'K{i}'] = df_source.iloc[i-start_row, 1] # Pmax\n",
    "    destination_ws[f'L{i}'] = 1 - df_other_sources.iloc[5, 1] # InService (inverted) since it is changed in the Pyomo model\n",
    "\n",
    "# Save the modified workbook\n",
    "destination_wb.save(destination_file_network)\n",
    "\n",
    "# Load offshore transmission network data\n",
    "df_source_offshore = pd.read_excel(source_file_network, usecols=[0,1,2], header=0, sheet_name=\"Offshore (for info)\")  # Read column A\n",
    "\n",
    "# Replace column 1 values with the maximum of column 1 and column 2 to get the max transport capacity\n",
    "df_source_offshore.iloc[:, 1] = df_source_offshore.iloc[:, 1].combine(df_source_offshore.iloc[:, 2], max)\n",
    "\n",
    "# Remove column C as it's no longer needed\n",
    "df_source_offshore.drop(df_source_offshore.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Keep only rows where the transmission capacity (column B) is non-zero\n",
    "df_source_offshore = df_source_offshore[df_source_offshore.iloc[:, 1] != 0]\n",
    "\n",
    "# Write processed offshore network data to the destination file\n",
    "for i, value in enumerate(df_source_offshore.iloc[:, 0], start=len(df_source) + start_row):\n",
    "    destination_ws[f'C{i}'] = value.split('-')[0]  # Bus from name in column B\n",
    "    destination_ws[f'D{i}'] = value.split('-')[1]  # Bus to name in column C\n",
    "\n",
    "    # Assign predefined static values from the other sources file\n",
    "    destination_ws[f'E{i}'] = df_other_sources.iloc[4, 1] # Circuit\n",
    "    destination_ws[f'I{i}'] = df_other_sources.iloc[9, 1] # TapAngle\n",
    "    destination_ws[f'J{i}'] = df_other_sources.iloc[10, 1] # TapRatio\n",
    "    destination_ws[f'K{i}'] = df_source_offshore.iloc[i-start_row-len(df_source), 1] # Pmax\n",
    "    destination_ws[f'L{i}'] = 1 - df_other_sources.iloc[5, 1] # InService (inverted) since it is changed in the Pyomo model\n",
    "# Save and close the final modified workbook\n",
    "destination_wb.save(destination_file_network)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_network}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Power_NTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define file paths for source data, template, and destination file\n",
    "# source_file_ntc = os.path.join(tyndp_dir, 'Line data/ReferenceGrid_Electricity.xlsx')\n",
    "# template_file_ntc = os.path.join(template_dir, 'Power_NTC.xlsx')\n",
    "# destination_file_ntc = os.path.join(destination_dir, 'Power_NTC.xlsx')\n",
    "\n",
    "# # If the destination file exists, remove it to ensure a clean start\n",
    "# if os.path.exists(destination_file_ntc):\n",
    "#     if is_file_open(destination_file_ntc):\n",
    "#         sys.exit(f\"File '{destination_file_ntc}' is currently open by another application.\")\n",
    "#     os.remove(destination_file_ntc)\n",
    "\n",
    "# # Copy the template file to the destination for modification\n",
    "# shutil.copy(template_file_ntc, destination_file_ntc)\n",
    "\n",
    "# # Load the destination workbook and select the active worksheet\n",
    "# destination_wb = load_workbook(destination_file_ntc)\n",
    "# destination_ws = destination_wb.active\n",
    "\n",
    "# # Load and process onshore transmission network data\n",
    "# df_source = pd.read_excel(source_file_ntc, usecols=[0,1,2], header=0, sheet_name=\"2030\")  # Read column A\n",
    "\n",
    "# # Keep only the rows where both columns B and C are not zero\n",
    "# df_source = df_source[~((df_source.iloc[:, 1] == 0) & (df_source.iloc[:, 2] == 0))]\n",
    "\n",
    "# # Define the starting row in the destination file for writing inflow data\n",
    "# start_row = 7\n",
    "\n",
    "# # Write the processed onshore network data to the destination file\n",
    "# for i, value in enumerate(df_source.iloc[:, 0], start=start_row):\n",
    "#     # Assign 'from' and 'to' zone names, and their respective transmission capacities\n",
    "#     destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[0]  # FromZone\n",
    "#     destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[1]  # ToZone\n",
    "#     destination_ws[f'D{i}'] = df_source.iloc[i-start_row, 1] # Pmax\n",
    "\n",
    "# # Write the reverse direction (from 'to' to 'from') with respective transmission capacities\n",
    "# for i, value in enumerate(df_source.iloc[:, 0], start=len(df_source) + start_row):\n",
    "#     destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[1]  # FromZone\n",
    "#     destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[0]  # ToZone\n",
    "#     destination_ws[f'D{i}'] = df_source.iloc[i-start_row-len(df_source) , 2] # Pmax\n",
    "\n",
    "\n",
    "# # Save the modified workbook to the destination\n",
    "# destination_wb.save(destination_file_ntc)\n",
    "\n",
    "# # Load and process offshore transmission network data\n",
    "# df_source_offshore = pd.read_excel(source_file_ntc, usecols=[0,1,2], header=0, sheet_name=\"Offshore (for info)\")  # Read column A\n",
    "\n",
    "# # Keep only the rows where both columns B and C are not zero\n",
    "# df_source_offshore = df_source_offshore[~((df_source_offshore.iloc[:, 1] == 0) & (df_source_offshore.iloc[:, 2] == 0))]\n",
    "\n",
    "# # Write the processed offshore network data to the destination file\n",
    "# for i, value in enumerate(df_source_offshore.iloc[:, 0], start=2*len(df_source) + start_row):\n",
    "#     # Assign 'from' and 'to' zone names, and their respective transmission capacities\n",
    "#     destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[0]  # FromZone\n",
    "#     destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[1]  # ToZone\n",
    "#     destination_ws[f'D{i}'] = df_source_offshore.iloc[i-start_row-2*len(df_source), 1] # Pmax\n",
    "\n",
    "# # Write the reverse direction (from 'to' to 'from') with respective transmission capacities\n",
    "# for i, value in enumerate(df_source_offshore.iloc[:, 0], start=2*len(df_source) + len(df_source_offshore) + start_row):\n",
    "#     destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[1]  # FromZone\n",
    "#     destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[0]  # ToZone\n",
    "#     destination_ws[f'D{i}'] = df_source_offshore.iloc[i-start_row-2*len(df_source)-len(df_source_offshore), 2] # Pmax\n",
    "\n",
    "# # Save and close the final modified workbook to the destination\n",
    "# destination_wb.save(destination_file_ntc)\n",
    "# destination_wb.close()\n",
    "\n",
    "# print(f\"Data saved successfully at: {destination_file_ntc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Power_RoR, Power_Storage, Power_VRES & Power_ThermalGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for source data, template files, and destination files\n",
    "if simulation_year == 2030:\n",
    "    folder_source_files_generators = os.path.join(tyndp_dir, 'PEMMDB2/2030/')\n",
    "elif simulation_year == 2040:\n",
    "    folder_source_files_generators = os.path.join(tyndp_dir, 'PEMMDB2/2040/')   \n",
    "elif simulation_year == 2050:\n",
    "    folder_source_files_generators = os.path.join(tyndp_dir, 'PEMMDB2/2050/')\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "source_file_prices = os.path.join(tyndp_dir, 'Prices/2023 06 22 TYNDP 2024 Commodity prices Final.xlsx')\n",
    "\n",
    "# Define template and destination file mappings for different power generation types\n",
    "files = {\n",
    "    \"RoR\": (os.path.join(template_dir, 'Power_RoR.xlsx'), os.path.join(destination_dir, 'Power_RoR.xlsx')),\n",
    "    \"Storage\": (os.path.join(template_dir, 'Power_Storage.xlsx'), os.path.join(destination_dir, 'Power_Storage.xlsx')),\n",
    "    \"VRES\": (os.path.join(template_dir, 'Power_VRES.xlsx'), os.path.join(destination_dir, 'Power_VRES.xlsx')),\n",
    "    \"Thermal\": (os.path.join(template_dir, 'Power_ThermalGen.xlsx'), os.path.join(destination_dir, 'Power_ThermalGen.xlsx')),\n",
    "}\n",
    "\n",
    "# Load price data from the source Excel file\n",
    "if simulation_year == 2030:\n",
    "    df_prices = pd.read_excel(source_file_prices, sheet_name=\"Matrix 2024\", usecols=[1, 2, 3], header=0)\n",
    "elif simulation_year == 2040:\n",
    "    df_prices = pd.read_excel(source_file_prices, sheet_name=\"Matrix 2024\", usecols=[1, 2, 4], header=0)\n",
    "elif simulation_year == 2050:\n",
    "    df_prices = pd.read_excel(source_file_prices, sheet_name=\"Matrix 2024\", usecols=[1, 2, 5], header=0)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "# Load data for various power generation sources\n",
    "df_other_sources_RoR = pd.read_excel(source_file_other_sources, sheet_name=\"Power_RoR\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_HS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_HS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_HPS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_HPS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_HPSCL = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_HPSCL\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_BESS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_BESS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_Wind = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_Wind\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_WindOff = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_WindOff\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_PV = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_PV\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_CSP = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_CSP\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_OtherRES = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_OtherRES\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_Nuclear = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_Nuclear\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalCCS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalCCS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteCCS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteCCS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasConvOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasConvOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasConvOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasConvOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTCCS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTCCS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasOCGTOld = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasOCGTOld\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasOCGTNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasOCGTNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LightOil = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LightOil\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_HeavyOilOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_HeavyOilOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_HeavyOilOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_HeavyOilOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_OilShaleOld = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_OilShaleOld\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_OilShaleNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_OilShaleNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTPresent1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTPresent1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTPresent2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTPresent2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_OtherNonRES = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_OtherNonRES\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Dictionary to store loaded workbooks and worksheets\n",
    "workbooks = {}\n",
    "worksheets = {}\n",
    "\n",
    "# Iterate through each power generation type and prepare destination files\n",
    "for key, (template_file, destination_file) in files.items():\n",
    "    # If the destination file already exists, remove it to start fresh\n",
    "    if os.path.exists(destination_file):\n",
    "        if is_file_open(destination_file):\n",
    "            sys.exit(f\"File '{destination_file}' is currently open by another application.\")\n",
    "        os.remove(destination_file)\n",
    "\n",
    "    # Copy the template file to the destination\n",
    "    shutil.copy(template_file, destination_file)\n",
    "\n",
    "    # Load the copied file as a workbook and select the active worksheet\n",
    "    destination_wb = load_workbook(destination_file)\n",
    "    destination_ws = destination_wb.active\n",
    "\n",
    "    # Store the workbook and worksheet in the dictionaries for later use\n",
    "    workbooks[key] = destination_wb\n",
    "    worksheets[key] = destination_ws\n",
    "\n",
    "# Get all the generator files that start with \"PEMMDB\" and end with \".xlsx\"\n",
    "generators_files = sorted(f for f in os.listdir(folder_source_files_generators) if (f.startswith(\"PEMMDB\") and f.endswith(\".xlsx\")))\n",
    "\n",
    "# Define the starting row in the destination file for writing generator data\n",
    "\n",
    "# Initialize row counters for each generator type\n",
    "cur_row_ror = 0\n",
    "cur_row_storage = 0\n",
    "cur_row_vres = 0\n",
    "cur_row_thermal = 0\n",
    "\n",
    "# Iterate through each generator file\n",
    "for filename in generators_files:\n",
    "    file_path = os.path.join(folder_source_files_generators, filename)  # Full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a valid file\n",
    "\n",
    "        # Load the generator data from the Excel file\n",
    "        generators_wb = pd.ExcelFile(file_path)\n",
    "        print(file_path)\n",
    "\n",
    "        # Load individual sheets from the generator Excel file\n",
    "        hydro_df = generators_wb.parse('Hydro')\n",
    "        thermal_df = generators_wb.parse('Thermal')\n",
    "        otherNonRes_df = generators_wb.parse('Other Non-RES')\n",
    "        battery_df = generators_wb.parse('Battery')\n",
    "        wind_df = generators_wb.parse('Wind')\n",
    "        solar_df = generators_wb.parse('Solar')\n",
    "        otherRes_df = generators_wb.parse('Other RES')\n",
    "\n",
    "        # Process data for Run-of-River (RoR) plants\n",
    "        if round((hydro_df.iloc[7, 1]+hydro_df.iloc[10, 1]),1) > 0:\n",
    "            row_start = 7\n",
    "            # Add data for RoR generation to the worksheet\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=2, value = filename.split('_')[1]+'ROR') # PP Name\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=3, value = df_other_sources_RoR.iloc[3, 1]) # Tec\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=5, value = df_other_sources_RoR.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=6, value = round(hydro_df.iloc[7, 1]+hydro_df.iloc[10, 1],1)) # MaxProd\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=7, value = df_other_sources_RoR.iloc[7, 1]) # MinProd\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=8, value = df_other_sources_RoR.iloc[8, 1]) # MaxCons\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=9, value = df_other_sources_RoR.iloc[9, 1]) # DisEffic\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=10, value = df_other_sources_RoR.iloc[10, 1]) # ChEffic\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=11, value = df_other_sources_RoR.iloc[11, 1]) # Qmax\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=12, value = df_other_sources_RoR.iloc[12, 1]) # Qmin\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=14, value = df_other_sources_RoR.iloc[14, 1]) # MinReserve\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=15, value = df_other_sources_RoR.iloc[15, 1]) # IniReserve\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=16, value = df_other_sources_RoR.iloc[16, 1]) # IsHydro\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=22, value = df_other_sources_RoR.iloc[22, 1]) # Ene2PowRatio\n",
    "            cell_17 = worksheets['RoR'].cell(row=row_start + cur_row_ror, column=17) #OMVarCost\n",
    "            if cell_17.value is None:\n",
    "                cell_17.value = 0\n",
    "            cell_18 = worksheets['RoR'].cell(row=row_start + cur_row_ror, column=18) #EnableInvest\n",
    "            if cell_18.value is None:\n",
    "                cell_18.value = 0\n",
    "            cell_19 = worksheets['RoR'].cell(row=row_start + cur_row_ror, column=19) #MaxInvest   \n",
    "            if cell_19.value is None:\n",
    "                cell_19.value = 0\n",
    "            cell_20 = worksheets['RoR'].cell(row=row_start + cur_row_ror, column=20) #InvestCostPerMW\n",
    "            if cell_20.value is None:\n",
    "                cell_20.value = 0\n",
    "            cell_21 = worksheets['RoR'].cell(row=row_start + cur_row_ror, column=21) #InvestCostPerMWh\n",
    "            if cell_21.value is None:\n",
    "                cell_21.value = 0\n",
    "\n",
    "            cur_row_ror += 1 # Move to the next row\n",
    "        row_start = 8\n",
    "        # Process data for Hydro Storage (HS)\n",
    "        if round(hydro_df.iloc[13, 1],1) > 0:\n",
    "            # Add data for Hydro Storage to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'HS') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_HS.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_HS.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(hydro_df.iloc[13, 1],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_HS.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = df_other_sources_Storage_HS.iloc[8, 1]) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = df_other_sources_Storage_HS.iloc[9, 1]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = df_other_sources_Storage_HS.iloc[10, 1]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_HS.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_HS.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_HS.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_HS.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=16, value = df_other_sources_Storage_HS.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_HS.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((hydro_df.iloc[12, 1]*1000)/hydro_df.iloc[13, 1],1)) # Ene2PowRatio\n",
    "            cell_18 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=18) # EnableInvest\n",
    "            if cell_18.value is None:\n",
    "                cell_18.value = 0\n",
    "            cell_19 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=19) # MaxInvest\n",
    "            if cell_19.value is None:\n",
    "                cell_19.value = 0\n",
    "            cell_20 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=20) # InvestCostPerMW\n",
    "            if cell_20.value is None:\n",
    "                cell_20.value = 0\n",
    "            cell_21 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=21) # InvestCostPerMWh\n",
    "            if cell_21.value is None:\n",
    "                cell_21.value = 0\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "        \n",
    "        # Process data for Hydro Pumped Storage (HPS)\n",
    "        if round(hydro_df.iloc[16, 1],1) > 0:\n",
    "            # Add data for Hydro Pumped Storage to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'HPS') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_HPS.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_HPS.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(hydro_df.iloc[16, 1],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_HPS.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = -round(hydro_df.iloc[17, 1],1)) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = df_other_sources_Storage_HPS.iloc[9, 1]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = df_other_sources_Storage_HPS.iloc[10, 1]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_HPS.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_HPS.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_HPS.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_HPS.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=16, value = df_other_sources_Storage_HPS.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_HPS.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((hydro_df.iloc[15, 1]*1000)/hydro_df.iloc[16, 1],1)) # Ene2PowRatio\n",
    "            cell_18 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=18) # EnableInvest\n",
    "            if cell_18.value is None:\n",
    "                cell_18.value = 0\n",
    "            cell_19 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=19) # MaxInvest\n",
    "            if cell_19.value is None:\n",
    "                cell_19.value = 0\n",
    "            cell_20 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=20) # InvestCostPerMW\n",
    "            if cell_20.value is None:\n",
    "                cell_20.value = 0\n",
    "            cell_21 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=21) # InvestCostPerMWh\n",
    "            if cell_21.value is None:\n",
    "                cell_21.value = 0\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Hydro Pumped Storage Closed Loop (HPSCl)\n",
    "        if round(hydro_df.iloc[20, 1],1) > 0:\n",
    "            # Add data for Hydro Pumped Storage Closed Loop to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'HPSCL') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_HPSCL.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_HPSCL.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(hydro_df.iloc[20, 1],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_HPSCL.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = -round(hydro_df.iloc[21, 1],1)) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = df_other_sources_Storage_HPSCL.iloc[9, 1]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = df_other_sources_Storage_HPSCL.iloc[10, 1]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_HPSCL.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_HPSCL.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_HPSCL.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_HPSCL.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=16, value = df_other_sources_Storage_HPSCL.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_HPSCL.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((hydro_df.iloc[19, 1]*1000)/hydro_df.iloc[20, 1],1)) # Ene2PowRatio\n",
    "            cell_18 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=18) # EnableInvest\n",
    "            if cell_18.value is None:\n",
    "                cell_18.value = 0\n",
    "            cell_19 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=19) # MaxInvest\n",
    "            if cell_19.value is None:\n",
    "                cell_19.value = 0\n",
    "            cell_20 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=20) # InvestCostPerMW\n",
    "            if cell_20.value is None:\n",
    "                cell_20.value = 0\n",
    "            cell_21 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=21) # InvestCostPerMWh\n",
    "            if cell_21.value is None:\n",
    "                cell_21.value = 0\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Batteries (BESS)\n",
    "        if round(battery_df.iloc[10, 2],1) > 0:\n",
    "            # Add data for Batteries to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'BESS') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_BESS.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_BESS.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(battery_df.iloc[10, 2],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_BESS.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = round(battery_df.iloc[10, 3],1)) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = battery_df.iloc[10, 6]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = battery_df.iloc[10, 6]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_BESS.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_BESS.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_BESS.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_BESS.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_BESS.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_BESS.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((battery_df.iloc[10, 4])/battery_df.iloc[10, 2],1)) # Ene2PowRatio\n",
    "            cell_18 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=18) # EnableInvest\n",
    "            if cell_18.value is None:\n",
    "                cell_18.value = 0\n",
    "            cell_19 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=19) # MaxInvest\n",
    "            if cell_19.value is None:\n",
    "                cell_19.value = 0\n",
    "            cell_20 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=20) # InvestCostPerMW\n",
    "            if cell_20.value is None:\n",
    "                cell_20.value = 0\n",
    "            cell_21 = worksheets['Storage'].cell(row=row_start + cur_row_storage, column=21) # InvestCostPerMWh\n",
    "            if cell_21.value is None:\n",
    "                cell_21.value = 0\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Wind power plants\n",
    "        if round(wind_df.iloc[6, 1],1) > 0:\n",
    "            # Add data for Wind power plants to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = filename.split('_')[1]+'WIND') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = df_other_sources_VRES_Wind.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = df_other_sources_VRES_Wind.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = round(wind_df.iloc[6, 1]*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_Wind.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=9, value = df_other_sources_VRES_Wind.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=11, value = df_other_sources_VRES_Wind.iloc[10, 1]) # OMVarCost\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=20, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=21, value=Datasource)  # Where the data for the entry comes from\n",
    "            cell_10 = worksheets['VRES'].cell(row=row_start + cur_row_vres, column=10) # InvestCost\n",
    "            if cell_10.value is None:\n",
    "                cell_10.value = 0\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Wind Offshore power plants\n",
    "        if round(wind_df.iloc[7, 1],1) > 0:\n",
    "            # Add data for Wind Offshore power plants to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = filename.split('_')[1]+'WINDOFF') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = df_other_sources_VRES_WindOff.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = df_other_sources_VRES_Wind.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = round(wind_df.iloc[6, 1]*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_WindOff.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=9, value = df_other_sources_VRES_WindOff.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=11, value = df_other_sources_VRES_WindOff.iloc[10, 1]) # OMVarCost\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=20, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=21, value=Datasource)  # Where the data for the entry comes from\n",
    "            cell_10 = worksheets['VRES'].cell(row=row_start + cur_row_vres, column=10) # InvestCost\n",
    "            if cell_10.value is None:\n",
    "                cell_10.value = 0\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Photovoltaic (PV) power plants\n",
    "        if round(solar_df.iloc[7, 1]+solar_df.iloc[8, 1],1) > 0:\n",
    "            # Add data for Photovoltaik power plants to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = filename.split('_')[1]+'PV') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = df_other_sources_VRES_PV.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = df_other_sources_VRES_PV.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = round((solar_df.iloc[7, 1]+solar_df.iloc[8, 1])*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_PV.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=9, value = df_other_sources_VRES_PV.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=11, value = df_other_sources_VRES_PV.iloc[10, 1]) # OMVarCost\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=20, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=21, value=Datasource)  # Where the data for the entry comes fromm\n",
    "            cell_10 = worksheets['VRES'].cell(row=row_start + cur_row_vres, column=10) # InvestCost\n",
    "            if cell_10.value is None:\n",
    "                cell_10.value = 0\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Concentrated Solar Power (CSP)\n",
    "        if round(solar_df.iloc[6, 1]+solar_df.iloc[9, 1],1) > 0:\n",
    "            # Add data for Concentrated Solar Power to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = filename.split('_')[1]+'CSP') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = df_other_sources_VRES_CSP.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = df_other_sources_VRES_CSP.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = round((solar_df.iloc[6, 1]+solar_df.iloc[9, 1])*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_CSP.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=9, value = df_other_sources_VRES_CSP.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=11, value = df_other_sources_VRES_CSP.iloc[10, 1]) # OMVarCost\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=20, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=21, value=Datasource)  # Where the data for the entry comes from\n",
    "            cell_10 = worksheets['VRES'].cell(row=row_start + cur_row_vres, column=10) # InvestCost\n",
    "            if cell_10.value is None:\n",
    "                cell_10.value = 0\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Other Renewable Energy Sources (OtherRES)\n",
    "        if round(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8],1) > 0:\n",
    "             # Add data for Other Renewable Energy Sources to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = filename.split('_')[1]+'OTHERRES') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = df_other_sources_VRES_OtherRES.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = df_other_sources_VRES_OtherRES.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = round(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8],1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_OtherRES.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=9, value = df_other_sources_VRES_OtherRES.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=11, value = df_other_sources_VRES_OtherRES.iloc[10, 1]) # OMVarCost\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=20, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=21, value=Datasource)  # Where the data for the entry comes from\n",
    "            cell_10 = worksheets['VRES'].cell(row=row_start + cur_row_vres, column=10) # InvestCost\n",
    "            if cell_10.value is None:\n",
    "                cell_10.value = 0\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Mapping of thermal power sources to their respective DataFrames\n",
    "        thermal_sources = {\n",
    "            \"NUCLEAR\": df_other_sources_Thermal_Nuclear,\n",
    "            \"COALOLD1\": df_other_sources_Thermal_CoalOld1,\n",
    "            \"COALOLD2\": df_other_sources_Thermal_CoalOld2,\n",
    "            \"COALNEW\": df_other_sources_Thermal_CoalNew,\n",
    "            \"COALCCS\": df_other_sources_Thermal_CoalCCS,\n",
    "            \"LIGNITEOLD1\": df_other_sources_Thermal_LigniteOld1,\n",
    "            \"LIGNITEOLD2\": df_other_sources_Thermal_LigniteOld2,\n",
    "            \"LIGNITENEW\": df_other_sources_Thermal_LigniteNew,\n",
    "            \"LIGNITECCS\": df_other_sources_Thermal_LigniteCCS,\n",
    "            \"GASCONVOLD1\": df_other_sources_Thermal_GasConvOld1,\n",
    "            \"GASCONVOLD2\": df_other_sources_Thermal_GasConvOld2,\n",
    "            \"GASCCGTOLD1\": df_other_sources_Thermal_GasCCGTOld1,\n",
    "            \"GASCCGTOLD2\": df_other_sources_Thermal_GasCCGTOld2,\n",
    "            \"GASCCGTNEW\": df_other_sources_Thermal_GasCCGTNew,\n",
    "            \"GASCCGTCCS\": df_other_sources_Thermal_GasCCGTCCS,\n",
    "            \"GASOCGTOLD\": df_other_sources_Thermal_GasOCGTOld,\n",
    "            \"GASOCGTNEW\": df_other_sources_Thermal_GasOCGTNew,\n",
    "            \"LIGHTOIL\": df_other_sources_Thermal_LightOil,\n",
    "            \"HEAVYOILOLD1\": df_other_sources_Thermal_HeavyOilOld1,\n",
    "            \"HEAVYOILOLD2\": df_other_sources_Thermal_HeavyOilOld2,\n",
    "            \"OILSHALEOLD\": df_other_sources_Thermal_OilShaleOld,\n",
    "            \"OILSHALENEW\": df_other_sources_Thermal_OilShaleNew,\n",
    "            \"GASCCGTPRESENT1\": df_other_sources_Thermal_GasCCGTPresent1,\n",
    "            \"GASCCGTPRESENT2\": df_other_sources_Thermal_GasCCGTPresent2,\n",
    "        }\n",
    "\n",
    "        # Define fuel price index for each thermal power source\n",
    "        price_indices = {\n",
    "            \"NUCLEAR\": 2, \"COALOLD1\": 7, \"COALOLD2\": 7, \"COALNEW\": 7, \"COALCCS\": 7, \"LIGNITEOLD1\": 3, \"LIGNITEOLD2\": 3, \"LIGNITENEW\": 3, \"LIGNITECCS\": 3,\n",
    "            \"GASCONVOLD1\": 8, \"GASCONVOLD2\": 8, \"GASCCGTOLD1\": 8, \"GASCCGTOLD2\": 8, \"GASCCGTPRESENT1\": 8,\n",
    "            \"GASCCGTPRESENT2\": 8, \"GASCCGTNEW\": 8, \"GASCCGTCCS\": 8, \"GASOCGTOLD\": 8, \"GASOCGTNEW\": 8,\n",
    "            \"LIGHTOIL\": 14, \"HEAVYOILOLD1\": 15, \"HEAVYOILOLD2\": 15, \"OILSHALEOLD\": 20, \"OILSHALENEW\": 20,\n",
    "        }\n",
    "\n",
    "        # Iterate over each thermal power source and write data to the worksheet\n",
    "        for idx, (source_name, df_source) in enumerate(thermal_sources.items(), start=10):\n",
    "            actual_idx = 10 + (idx - 10) * 2  # Ensure idx increments by 2 instead of 1\n",
    "\n",
    "            # Process only if MaxProd is greater than 0\n",
    "            if round(thermal_df.iloc[actual_idx, 2], 1) > 0:\n",
    "                price_index = price_indices.get(source_name)  # Get fuel price index\n",
    "\n",
    "                # Extract country code from filename\n",
    "                filename_part = filename.split('_')[1]\n",
    "                if filename_part[2:4] == '00':\n",
    "                    countryCode = filename_part[:2]  # First two characters\n",
    "                else:\n",
    "                    countryCode = filename_part  # Full identifier\n",
    "                row_start = 8\n",
    "                # Write data to the 'Thermal' worksheet\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=3, value=filename.split('_')[1] + source_name)  # PP Name\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=4, value=df_source.iloc[3, 1])  # Tec\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=5, value=filename.split('_')[1])  # Node/Businfo\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=6, value=df_source.iloc[5, 1])  # ExisUnit\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=7, value=round(thermal_df.iloc[actual_idx, 2], 1))  # MaxProd\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=8, value=df_source.iloc[7, 1])  # MinProd\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=9, value=round(thermal_df.iloc[actual_idx, 2], 1))  # RampUp\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=10, value=round(thermal_df.iloc[actual_idx, 2], 1))  # RampDw\n",
    "                \n",
    "                # Determine fuel cost based on country and source type\n",
    "                if (\"lignite\" in source_name.lower() and countryCode in ['BG', 'MK', 'CZ']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=round(df_prices.iloc[3, 2] * 3.6 , 4))\n",
    "                elif (\"lignite\" in source_name.lower() and countryCode in ['SK', 'DE', 'RS', 'PL', 'ME', 'UKNI', 'BA', 'IE']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=round(df_prices.iloc[4, 2] * 3.6 , 4)) # FuelCost from â‚¬/GJ in â‚¬/MWh\n",
    "                elif (\"lignite\" in source_name.lower() and countryCode in ['SI', 'RO', 'HU']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=round(df_prices.iloc[5, 2] * 3.6 , 4))\n",
    "                elif (\"lignite\" in source_name.lower() and countryCode in ['GR', 'TR']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=round(df_prices.iloc[6, 2] * 3.6 , 4))\n",
    "                elif (\"lignite\" in source_name.lower()):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=99999)\n",
    "                else:\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=round(df_prices.iloc[price_index, 2] * 3.6 , 4))  # FuelCost\n",
    "                \n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17, value=round(df_source.iloc[14, 1], 4))  # Efficiency\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=18, value=round(df_source.iloc[15, 1]/ 860.42065,4))  # Consumption in MWh/h\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=19, value=df_source.iloc[16, 1])  # OMVarCost\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=20, value=round(df_source.iloc[17, 1]/ 860.42065,4))  # StartUpCost in MW\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=22, value=df_source.iloc[19, 1])  # EnableInvest\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=25, value=round(df_source.iloc[22, 1] * 3.6, 3))  # CO2Emis\n",
    "                worksheets['Thermal'].cell(row=row_start+cur_row_vres, column=30, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "                worksheets['Thermal'].cell(row=row_start+cur_row_vres, column=31, value=Datasource)  # Where the data for the entry comes from\n",
    "                \n",
    "                cell_11 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=11) # MinUpTime\n",
    "                if cell_11.value is None:\n",
    "                    cell_11.value = 0\n",
    "                cell_12 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=12) # MinDownTime\n",
    "                if cell_12.value is None:\n",
    "                    cell_12.value = 0\n",
    "                cell_17 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17) # Efficiency\n",
    "                if cell_17.value is None:\n",
    "                    cell_17.value = 1\n",
    "                cell_23 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=23) # InvestmentCost\n",
    "                if cell_23.value is None:\n",
    "                    cell_23.value = 0\n",
    "                cur_row_thermal += 1  # Move to the next row\n",
    "\n",
    "        # Save workbook after processing all thermal power sources\n",
    "        # Check if the file is open before saving\n",
    "        if is_file_open(files[\"Thermal\"][1]):\n",
    "            sys.exit(f\"File '{files['Thermal'][1]}' is currently open by another application. Please close it and try again.\")\n",
    "        workbooks[\"Thermal\"].save(files[\"Thermal\"][1])\n",
    "\n",
    "        if round(otherNonRes_df.iloc[7, 2],1) > 0:\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=3, value=filename.split('_')[1] + 'OTHERNONRES')  # PP Name\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=4, value=df_other_sources_Thermal_OtherNonRES.iloc[3, 1])  # Tec\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=5, value=filename.split('_')[1])  # Node/Businfo\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=6, value=df_other_sources_Thermal_OtherNonRES.iloc[5, 1])  # ExisUnit\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=7, value=round(otherNonRes_df.iloc[7, 2], 1))  # MaxProd\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=8, value=df_other_sources_Thermal_OtherNonRES.iloc[7, 1])  # MinProd\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=9, value=round(otherNonRes_df.iloc[7, 2], 1))  # RampUp\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=10, value=round(otherNonRes_df.iloc[7, 2], 1))  # RampDw\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=round(df_prices.iloc[12, 2] * 3.6 , 4))  # FuelCost from â‚¬/GJ in â‚¬/MWh\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17, value=round( df_other_sources_Thermal_OtherNonRES.iloc[14, 1], 4))  # Efficiency\n",
    "            cell_17 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17)\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=18, value=round(df_other_sources_Thermal_OtherNonRES.iloc[15, 1]/ 860.42065,4))  # Consumption in MWh/h\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=19, value=df_other_sources_Thermal_OtherNonRES.iloc[16, 1])  # OMVarCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=20, value=round(df_other_sources_Thermal_OtherNonRES.iloc[17, 1]/ 860.42065,4))  # StartUpCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=22, value=df_other_sources_Thermal_OtherNonRES.iloc[19, 1])  # EnableInvest\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=25, value=round(df_other_sources_Thermal_OtherNonRES.iloc[22, 1] * 3.6, 3))  # CO2Emis\n",
    "            worksheets['Thermal'].cell(row=row_start+cur_row_vres, column=30, value=f\"V2G_{simulation_year}_{scenario}\")  # Which package this belongs to\n",
    "            worksheets['Thermal'].cell(row=row_start+cur_row_vres, column=31, value=Datasource)  # Where the data for the entry comes from\n",
    "            # Set 0 to columns if empty since the Pyomo model requires values in these columns\n",
    "            cell_11 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=11) # MinUpTime\n",
    "            if cell_11.value is None:\n",
    "                cell_11.value = 0\n",
    "            cell_12 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=12) # MinDownTime\n",
    "            if cell_12.value is None:\n",
    "                cell_12.value = 0\n",
    "            cell_17 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17) # Efficiency\n",
    "            if cell_17.value is None:\n",
    "                cell_17.value = 1\n",
    "            cell_23 = worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=23) # InvestmentCost\n",
    "            if cell_23.value is None:\n",
    "                cell_23.value = 0\n",
    "\n",
    "            cur_row_thermal += 1 # Move to the next row\n",
    "\n",
    "# Save and close notebooks\n",
    "workbooks[\"RoR\"].save(files[\"RoR\"][1])\n",
    "workbooks[\"RoR\"].close()\n",
    "workbooks[\"Storage\"].save(files[\"Storage\"][1])\n",
    "workbooks[\"Storage\"].close()\n",
    "workbooks[\"VRES\"].save(files[\"VRES\"][1])\n",
    "workbooks[\"VRES\"].close()\n",
    "workbooks[\"Thermal\"].save(files[\"Thermal\"][1])\n",
    "workbooks[\"Thermal\"].close()\n",
    "\n",
    "print(f\"Generator data saved successfully copied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Power_VRESProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for source and destination files\n",
    "if simulation_year == 2030:\n",
    "    folder_source_files_VRESProfiles = os.path.join(tyndp_dir, 'PECD/2030')\n",
    "    folder_source_files_OtherRESProfiles = os.path.join(tyndp_dir, 'PEMMDB2/2030')\n",
    "elif simulation_year == 2040:\n",
    "    folder_source_files_VRESProfiles = os.path.join(tyndp_dir, 'PECD/2040')\n",
    "    folder_source_files_OtherRESProfiles = os.path.join(tyndp_dir, 'PEMMDB2/2040')\n",
    "elif simulation_year == 2050:\n",
    "    folder_source_files_VRESProfiles = os.path.join(tyndp_dir, 'PECD/2050')\n",
    "    folder_source_files_OtherRESProfiles = os.path.join(tyndp_dir, 'PEMMDB2/2050')\n",
    "else:\n",
    "    sys.exit(f\"Invalid simulation year: {simulation_year}. Please use 2030, 2040, or 2050.\")\n",
    "\n",
    "template_file_VRESProfiles = os.path.join(template_dir, 'Power_VRESProfiles.xlsx')\n",
    "destination_file_VRESProfiles = os.path.join(destination_dir, 'Power_VRESProfiles.xlsx')\n",
    "\n",
    "# Prepare the destination file by removing it if it already exists\n",
    "if os.path.exists(destination_file_VRESProfiles):\n",
    "    if is_file_open(destination_file_VRESProfiles):\n",
    "        sys.exit(f\"File '{destination_file_VRESProfiles}' is currently open by another application.\")\n",
    "    os.remove(destination_file_VRESProfiles)\n",
    "\n",
    "# Copy the template file to the destination directory\n",
    "shutil.copy(template_file_VRESProfiles, destination_file_VRESProfiles)\n",
    "\n",
    "# If there is no file for Wind_Offshore_2030_BEOF, copy the Wind_Offshore_2030_BE00 file and rename it\n",
    "if not os.path.exists(os.path.join(tyndp_dir, 'PECD/2030/PECD_Wind_Offshore_2030_BEOF_edition 2023.2.csv')):\n",
    "    shutil.copy(os.path.join(tyndp_dir, 'PECD/2030/PECD_Wind_Offshore_2030_BE00_edition 2023.2.csv'), os.path.join(tyndp_dir, 'PECD/2030/PECD_Wind_Offshore_2030_BEOF_edition 2023.2.csv'))\n",
    "\n",
    "# Load the destination workbook and worksheet\n",
    "destination_wb = load_workbook(destination_file_VRESProfiles)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Get the list of VRES profile files to process\n",
    "vres_profiles_files = sorted(f for f in os.listdir(folder_source_files_VRESProfiles) if (f.startswith(\"PECD\") and f.endswith(\".csv\")))\n",
    "\n",
    "# Starting row in destination file\n",
    "row_start = 8\n",
    "\n",
    "# Process each VRES profile file\n",
    "for filename in vres_profiles_files:\n",
    "    file_path = os.path.join(folder_source_files_VRESProfiles, filename)  # Full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a valid file\n",
    "\n",
    "        # Identify the type of technology from the filename\n",
    "        matched_tec = [tec for tec in ['_CSP_noStorage_', '_LFSolarPV_', '_LFSolarPVRooftop_', '_Wind_Offshore_', '_Wind_Onshore_'] if tec in filename]\n",
    "        if matched_tec:\n",
    "            print(file_path) # Log the file being processed\n",
    "        else:\n",
    "            continue # Skip files that don't match the expected technologies\n",
    "            \n",
    "        # Load the VRES profile data (skip header rows, select the first 8760 rows for hourly data)\n",
    "        vres_profiles = pd.read_csv(file_path, skiprows=10, header=0, nrows=8760)\n",
    "\n",
    "        # Check if the selected year is present in the columns (year columns start from index 2)\n",
    "        year_columns = vres_profiles.columns[2:]\n",
    "        for y in year_columns:\n",
    "            if '.' in y:\n",
    "                year_columns = year_columns.str.replace('.0', '') # Remove .0 suffix if present\n",
    "        if (str(cy_year) not in year_columns):\n",
    "            print(f\"Year {cy_year} not found in sheet {filename}. Skipping node.\")\n",
    "            continue # Skip if the year is not found\n",
    "\n",
    "        # Get the column index for the selected year\n",
    "        year_col_idx = year_columns.get_loc(str(cy_year)) + 2  # Adjust for 1-based index in Excel\n",
    "\n",
    "\n",
    "        # Extract the time series for the selected year (8760 hours)\n",
    "        time_series = vres_profiles.iloc[:, year_col_idx].fillna(0) # Fill missing values with 0\n",
    "\n",
    "        # Skip if the entire time series is zero\n",
    "        if time_series.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Write data to the destination worksheet (PP name, node information)\n",
    "        destination_ws[f'C{row_start}'] = 'rp01' # Periode\n",
    "        destination_ws[f'D{row_start}'] = filename.split('_')[-2]  # Write node name (second last part of the filename)\n",
    "        if filename.split('_')[1] + filename.split('_')[2]  == 'CSPnoStorage':\n",
    "            destination_ws[f'D{row_start}'] = (destination_ws[f'D{row_start}'].value or '') + 'CSP'\n",
    "        elif filename.split('_')[1] in ['LFSolarPV', 'LFSolarPVRooftop']:\n",
    "            destination_ws[f'D{row_start}'] = (destination_ws[f'D{row_start}'].value or '') + 'PV'\n",
    "        elif filename.split('_')[1]  + filename.split('_')[2] == 'WindOffshore':\n",
    "            destination_ws[f'D{row_start}'] = (destination_ws[f'D{row_start}'].value or '') + 'WINDOFF'\n",
    "        elif filename.split('_')[1] + filename.split('_')[2] == 'WindOnshore':\n",
    "            destination_ws[f'D{row_start}'] = (destination_ws[f'D{row_start}'].value or '') + 'WIND'\n",
    "        else:\n",
    "            continue  # Skip if the technology is not recognized\n",
    "        destination_ws[f'E{row_start}'] = f\"V2G_{simulation_year}_{scenario}\" # Which package this belongs to\n",
    "        destination_ws[f'F{row_start}'] = Datasource # Where the data for the entry comes from\n",
    "\n",
    "        # Write the time series data (8760 hours) starting from column G\n",
    "        column_start = 7\n",
    "        for cf in time_series: # Iterate over the time series values\n",
    "            destination_ws.cell(row=row_start, column=column_start, value=round(cf,4))\n",
    "            column_start += 1 # Move to the next column\n",
    "    \n",
    "        row_start += 1  # Move to the next row for the next entry\n",
    "\n",
    "# Process Other RES profile files\n",
    "otherRES_profiles_files = sorted(f for f in os.listdir(folder_source_files_OtherRESProfiles) if (f.startswith(\"PEMMDB\") and f.endswith(\".xlsx\")))\n",
    "\n",
    "for filename in otherRES_profiles_files:\n",
    "    file_path = os.path.join(folder_source_files_OtherRESProfiles, filename)  # Full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a valid file\n",
    "\n",
    "        # Load the Excel file and process the data\n",
    "        generators_wb = pd.ExcelFile(file_path)\n",
    "        print(file_path) # Log the file being processed\n",
    "\n",
    "        otherRes_df = generators_wb.parse('Other RES')\n",
    "\n",
    "        # Check if the total generation for the selected year is greater than zero\n",
    "        if round(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8],1) > 0:\n",
    "            destination_ws[f'C{row_start}'] = 'rp01' # Periode\n",
    "            destination_ws[f'D{row_start}'] = filename.split('_')[1] +'OTHERRES' # Node name\n",
    "            destination_ws[f'E{row_start}'] = f\"V2G_{simulation_year}_{scenario}\" # Which package this belongs to\n",
    "            destination_ws[f'F{row_start}'] = Datasource # Where the data for the entry comes from\n",
    "            # Write the time series data (8760 hours) starting from column G\n",
    "            column_start = 7\n",
    "            for i in range(8760): # Iterate over the time series values\n",
    "                destination_ws.cell(row=row_start, column=column_start, value=round((otherRes_df.iloc[9, 4]+otherRes_df.iloc[9, 5]+otherRes_df.iloc[9, 6]+otherRes_df.iloc[9, 7]+otherRes_df.iloc[9, 8])/(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8]),4))\n",
    "                column_start += 1 # Move to the next column\n",
    "        \n",
    "            row_start += 1  # Move to the next row for the next entry\n",
    "\n",
    "# Save and close the modified workbook to the destination\n",
    "destination_wb.save(destination_file_VRESProfiles)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_VRESProfiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Post-Tasks\n",
    "This includes extracting or generating electrical parameters for power lines from PyPSA data and removing unnecessary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Electric Parameters for Network\n",
    "The electrical parameters (X values) for power lines are sourced from PyPSA data stored in PyPSA_Data/Power_Network_PyPSA.xlsx.\n",
    "If a connection is not available in the PyPSA data, a rough estimate is derived based on the relationship between X and Pmax within the existing PyPSA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: [p.u.].1, dtype: float64\n",
      "0     600\n",
      "1     400\n",
      "2     500\n",
      "3     250\n",
      "4    1200\n",
      "Name: [MW], dtype: int64\n",
      "Line parameters updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source and destination files\n",
    "source_file_line_parameters = os.path.join(pypsa_dir, 'Power_Network_PyPSA.xlsx')\n",
    "destination_file_Network = os.path.join(destination_dir, 'Power_Network.xlsx')\n",
    "\n",
    "if is_file_open(destination_file_Network):\n",
    "    sys.exit(f\"File '{destination_file_Network}' is currently open by another application.\")\n",
    "\n",
    "# Load data from the source and destination Excel files\n",
    "df_pypsa_lines = pd.read_excel(source_file_line_parameters, skiprows=6) # Data from PyPSA source file\n",
    "#print(df_pypsa_lines.head()) # Print the first few rows of the PyPSA line data\n",
    "df_power_network = pd.read_excel(destination_file_Network, skiprows=6) # Data from the destination network file\n",
    "#print(df_power_network.head()) # Print the first few rows of the PyPSA line data\n",
    "# Create a combined identifier by concatenating columns 1 and 2, removing spaces\n",
    "df_pypsa_lines[\"combined\"] = (df_pypsa_lines.iloc[:, 1] + df_pypsa_lines.iloc[:, 2]).str.replace(\" \", \"\", regex=True)\n",
    "df_pypsa_lines = df_pypsa_lines.drop_duplicates(subset=\"combined\") # Remove duplicate combined entries\n",
    "\n",
    "# Create a combined identifier for the power network file, similar to the PyPSA file\n",
    "df_power_network[\"combined\"] = df_power_network[\"combined\"] = (df_power_network.iloc[:, 1] + df_power_network.iloc[:, 2]).str.replace(\" \", \"\", regex=True)\n",
    "\n",
    "# Map the line parameters from the PyPSA file to the destination network file based on the \"combined\" column\n",
    "df_power_network.iloc[:, 6] = df_power_network[\"combined\"].map(\n",
    "    df_pypsa_lines.set_index(\"combined\").iloc[:, 6]\n",
    ")\n",
    "print(df_power_network.iloc[:, 6].head()) # Print the first few rows of the line data\n",
    "# Fill missing values in the line parameters using a mathematical formula\n",
    "df_power_network.iloc[:, 10] = pd.to_numeric(df_power_network.iloc[:, 10], errors='coerce')\n",
    "print(df_power_network.iloc[:, 10].head()) # Print the first few rows of the line data\n",
    "df_power_network.iloc[:, 6] = df_power_network.iloc[:, 6].fillna(\n",
    "    14527 * df_power_network.iloc[:, 10] ** (-0.77)\n",
    ")\n",
    "\n",
    "# Calculate the line parameters in pu\n",
    "df_power_network.iloc[:, 6] = round(df_power_network.iloc[:, 6]/(((380*10**3)**2)/(100*10**6)), 15)\n",
    "\n",
    "# Load the destination workbook and worksheet for saving the changes\n",
    "destination_wb = load_workbook(destination_file_Network)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Write the adjusted line parameters into the destination worksheet, starting from row 8\n",
    "start_row = 8\n",
    "for i, value in enumerate(df_power_network.iloc[:, 0], start=start_row):\n",
    "    destination_ws[f'G{i}'] = df_power_network.iloc[i-start_row, 6]\n",
    "\n",
    "# Save the modified workbook to the destination\n",
    "destination_wb.save(destination_file_Network)\n",
    "destination_wb.close()\n",
    "\n",
    "print(\"Line parameters updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Cleanup\n",
    "Removes unnecessary data that was copied during processing:\n",
    "\n",
    "- Deletes demand and generators from nodes that are not listed in *Power_BusInfo.xlsx*.\n",
    "- Removes inflows for RoR or storage units that are not listed in *Power_RoR.xlsx* or *Power_Storage*.\n",
    "- Deletes NTCs and power lines that reference buses not found in *P*ower_BusInfo.xlsx*.\n",
    "- Removes VRES profiles for VRES generators units that are not listed in *Power_VRES*.\n",
    "\n",
    "**IMPORTANT**:\n",
    "If you want to include only a subset of countries in the final dataset, first remove all unwanted countries from *Power_BusInfo.xlsx* in the specified `destination_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Power_Demand\n",
    "Deletes demand from nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power Bus Information and Power Demand data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_demand = os.path.join(destination_dir, 'Power_Demand.xlsx')\n",
    "\n",
    "if is_file_open(file_demand):\n",
    "    sys.exit(f\"File '{file_demand}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx and extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_Demand.xlsx to filter nodes based on validity\n",
    "demand_wb = load_workbook(file_demand) # Load the Power Demand workbook\n",
    "demand_ws = demand_wb.active\n",
    "\n",
    "# Collect rows to delete based on invalid node values\n",
    "delete_rows = [] # List to store rows that should be deleted\n",
    "for row_idx, row in enumerate(demand_ws.iter_rows(min_row=8, min_col=4, max_col=4, values_only=True), start=8):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check for invalid or missing nodes\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} will be deleted.\")\n",
    "\n",
    "# Delete rows in reverse order to avoid index shifting during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    demand_ws.delete_rows(row_idx) # Delete invalid rows from the workbook\n",
    "\n",
    "# Save and close the updated Power_Demand.xlsx\n",
    "demand_wb.save(file_demand)\n",
    "demand_wb.close()\n",
    "\n",
    "print(\"Power Demand data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Power_RoR\n",
    "Deletes RoR generators with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power Bus Information and Power RoR data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_RoR = os.path.join(destination_dir, 'Power_RoR.xlsx')\n",
    "\n",
    "if is_file_open(file_RoR):\n",
    "    sys.exit(f\"File '{file_RoR}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "# Load Power_RoR.xlsx to filter nodes based on validity\n",
    "ror_wb = load_workbook(file_RoR) # Load the Power RoR workbook\n",
    "ror_ws = ror_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(ror_ws.iter_rows(min_row=7, min_col=4, max_col=4, values_only=True), start=7):\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    ror_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_RoR.xlsx with updated data\n",
    "ror_wb.save(file_RoR)\n",
    "ror_wb.close()\n",
    "\n",
    "print(\"Power RoR data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Power_Storage\n",
    "Deletes storage units with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power Bus Information and Power Storage data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_storage = os.path.join(destination_dir, 'Power_Storage.xlsx')\n",
    "\n",
    "if is_file_open(file_storage):\n",
    "    sys.exit(f\"File '{file_storage}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_RoR.xlsx to filter nodes based on validity\n",
    "storage_wb = load_workbook(file_storage)\n",
    "storage_ws = storage_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(storage_ws.iter_rows(min_row=7, min_col=4, max_col=4, values_only=True), start=7):\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    storage_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_Storage.xlsx with updated data\n",
    "storage_wb.save(file_storage)\n",
    "storage_wb.close()\n",
    "\n",
    "print(\"Power Storage data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Power_VRES\n",
    "Deletes VRES generators with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power Bus Information and Power VRES data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_VRES = os.path.join(destination_dir, 'Power_VRES.xlsx')\n",
    "\n",
    "if is_file_open(file_VRES):\n",
    "    sys.exit(f\"File '{file_VRES}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "# Load Power_VRES.xlsx to filter nodes based on validity\n",
    "vres_wb = load_workbook(file_VRES) # Load the Power VRES workbook\n",
    "vres_ws = vres_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(vres_ws.iter_rows(min_row=8, min_col=5, max_col=5, values_only=True), start=8):\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    vres_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "    \n",
    "vres_wb.save(file_VRES)\n",
    "vres_wb.close()\n",
    "\n",
    "print(\"Power VRES data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.5 Power_ThermalGen\n",
    "Deletes thermal generators with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power Bus Information and Power ThermalGen data\n",
    "ile_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_thermals = os.path.join(destination_dir, 'Power_ThermalGen.xlsx')\n",
    "\n",
    "if is_file_open(file_thermals):\n",
    "    sys.exit(f\"File '{file_thermals}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "\n",
    "# Load Power_ThermalGen.xlsx to filter nodes based on validity\n",
    "thermals_wb = load_workbook(file_thermals) # Load the Power ThermalGen workbook\n",
    "thermals_ws = thermals_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(thermals_ws.iter_rows(min_row=8, min_col=5, max_col=5, values_only=True), start=8):\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    thermals_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Identify and remove duplicate rows based on columns 4 (D) and 5 (E)\n",
    "seen_pairs = set()\n",
    "duplicate_rows = []\n",
    "\n",
    "for row_idx, row in enumerate(thermals_ws.iter_rows(min_row=8, min_col=3, max_col=4, values_only=True), start=8):\n",
    "    pair = (row[0], row[1])\n",
    "    if pair in seen_pairs:\n",
    "        duplicate_rows.append(row_idx)\n",
    "        print(f\"Row {row_idx} with duplicate pair {pair} marked for deletion.\")\n",
    "    else:\n",
    "        seen_pairs.add(pair)\n",
    "\n",
    "# Delete duplicate rows in reverse to avoid row shift\n",
    "print(\"Deleting duplicate rows...\")\n",
    "for row_idx in reversed(duplicate_rows):\n",
    "    thermals_ws.delete_rows(row_idx)\n",
    "\n",
    "# Save and close the filtered Power_ThermalGen.xlsx with updated data\n",
    "thermals_wb.save(file_thermals)\n",
    "thermals_wb.close()\n",
    "\n",
    "print(\"Power ThermalGen data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Power_Inflows\n",
    "Removes inflows for RoR and storage units that are not listed in *Power_RoR.xlsx* or *Power_Storage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power RoR, Power Storage, and Power Inflows\n",
    "file_ror = os.path.join(destination_dir, 'Power_RoR.xlsx')\n",
    "file_storage = os.path.join(destination_dir, 'Power_Storage.xlsx')\n",
    "file_inflows = os.path.join(destination_dir, 'Power_Inflows.xlsx')\n",
    "\n",
    "if is_file_open(file_inflows):\n",
    "    sys.exit(f\"File '{file_inflows}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_RoR.xlsx to extract valid inflow nodes\n",
    "ror_wb = load_workbook(file_ror, data_only=True)\n",
    "ror_ws = ror_wb.active\n",
    "\n",
    "# Load Power_Storage.xlsx to extract valid storage nodes\n",
    "storage_wb = load_workbook(file_storage, data_only=True)\n",
    "storage_ws = storage_wb.active\n",
    "\n",
    "valid_inflows = set() # Set to store valid inflow node IDs\n",
    "\n",
    "# Extract valid nodes from Power_RoR and Power_Storage workbooks\n",
    "for row in ror_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_inflows.add(str(row[0])) # Add valid inflows to the set\n",
    "\n",
    "for row in storage_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_inflows.add(str(row[0])) # Add valid storage nodes to the set\n",
    "\n",
    "# Load Power_Inflows.xlsx to filter rows based on valid inflow nodes\n",
    "inflows_wb = load_workbook(file_inflows) # Load the Power Inflows workbook\n",
    "inflows_ws = inflows_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing inflow nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(inflows_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_inflows: # Check if the inflow node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    inflows_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_Inflows.xlsx with updated data\n",
    "inflows_wb.save(file_inflows)\n",
    "inflows_wb.close()\n",
    "\n",
    "print(\"Power Inflows data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7 Power_NTC\n",
    "Deletes NTCs that reference buses not found in *P*ower_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define file paths for Power BusInfo and Power NTC data\n",
    "# file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "# file_NTC = os.path.join(destination_dir, 'Power_NTC.xlsx')\n",
    "\n",
    "# if is_file_open(file_NTC):\n",
    "#     sys.exit(f\"File '{file_NTC}' is currently open by another application.\")\n",
    "\n",
    "# # Load Power_BusInfo.xlsx to extract valid node IDs\n",
    "# bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook in data-only mode\n",
    "# bus_ws = bus_wb.active\n",
    "\n",
    "# valid_nodes = set() # Set to store valid node IDs\n",
    "\n",
    "# # Extract valid nodes from Power_BusInfo\n",
    "# for row in bus_ws.iter_rows(min_row=8, min_col=4, max_col=4, values_only=True):\n",
    "#     if row[0] is not None:\n",
    "#         valid_nodes.add(str(row[0]))\n",
    "\n",
    "# # Load Power_NTC.xlsx to filter rows based on valid nodes\n",
    "# ntc_wb = load_workbook(file_NTC) # Load the Power NTC workbook\n",
    "# ntc_ws = ntc_wb.active\n",
    "\n",
    "# # Identify rows to delete based on invalid or missing node IDs (column 2)\n",
    "# delete_rows = [] # List to store rows that need to be deleted\n",
    "# for row_idx, row in enumerate(ntc_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True), start=7):\n",
    "#     if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "#         delete_rows.append(row_idx) # Add row index to the delete list\n",
    "#         print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# # Identify rows to delete based on invalid or missing node IDs (column 3)\n",
    "# for row_idx, row in enumerate(ntc_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True), start=7):\n",
    "#     if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "#         delete_rows.append(row_idx) # Add row index to the delete list\n",
    "#         print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# # Remove duplicate row indices and sort in descending order to avoid shifting issues during deletion\n",
    "# delete_rows = sorted(set(delete_rows))\n",
    "\n",
    "# # Delete rows in reverse order to prevent issues with shifting after deletion\n",
    "# print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "# for row_idx in reversed(delete_rows):\n",
    "#     ntc_ws.delete_rows(row_idx) # Delete the rows\n",
    "\n",
    "# # Save and close the updated Power_NTC.xlsx with the filtered data\n",
    "# ntc_wb.save(file_NTC)\n",
    "# ntc_wb.close()\n",
    "\n",
    "# print(\"Power NTC data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.8 Power_Network\n",
    "Deletes lines that reference buses not found in *P*ower_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power BusInfo and Power Network data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_Network = os.path.join(destination_dir, 'Power_Network.xlsx')\n",
    "\n",
    "if is_file_open(file_Network):\n",
    "    sys.exit(f\"File '{file_Network}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid node IDs\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook in data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "\n",
    "# Extract valid nodes from Power_BusInfo\n",
    "for row in bus_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_Network.xlsx to filter rows based on valid nodes\n",
    "network_wb = load_workbook(file_Network) # Load the Power Network workbook\n",
    "network_ws = network_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing node IDs (column 2)\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(network_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True), start=8):\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Identify second rows to delete based on invalid or missing node IDs (column 3)\n",
    "for row_idx, row in enumerate(network_ws.iter_rows(min_row=8, min_col=4, max_col=4, values_only=True), start=8):\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Remove duplicate row indices and sort in descending order to avoid shifting issues during deletion\n",
    "delete_rows = sorted(set(delete_rows))\n",
    "\n",
    "# Delete rows in reverse order to prevent issues with shifting after deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    network_ws.delete_rows(row_idx) # Delete the rows\n",
    "\n",
    "# Save the updated Power_Network.xlsx with the filtered data\n",
    "network_wb.save(file_Network)\n",
    "network_wb.close()\n",
    "\n",
    "print(\"Power Network data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.9 Power_VRESProfiles\n",
    "Removes VRES profiles for VRES generators units that are not listed in *Power_VRES*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power VRES and Power VRES Profiles data\n",
    "file_VRES = os.path.join(destination_dir, 'Power_VRES.xlsx')\n",
    "file_VRESProfiles = os.path.join(destination_dir, 'Power_VRESProfiles.xlsx')\n",
    "\n",
    "if is_file_open(file_VRESProfiles):\n",
    "    sys.exit(f\"File '{file_VRESProfiles}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_VRES.xlsx and extract valid node identifiers\n",
    "vres_wb = load_workbook(file_VRES, data_only=True) # Load workbook in data-only mode\n",
    "vres_ws = vres_wb.active\n",
    "\n",
    "valid_nodes = set()# Set to store valid combined node identifiers\n",
    "\n",
    "# Extract valid profiles by combining information from column 3 Generator # Old Version doen't work in new Power_VRESProfiles\n",
    "for row in vres_ws.iter_rows(min_row=8, min_col=3, max_col=3, values_only=True):\n",
    "        valid_nodes.add(str(row[0]) )# Add valid node IDs to the set\n",
    "\n",
    "# Load Power_VRESProfiles.xlsx to filter rows based on valid inflows\n",
    "vresprofiles_wb = load_workbook(file_VRESProfiles) # Load the Power VRES Profiles workbook\n",
    "vresprofiles_ws = vresprofiles_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing combined identifiers (columns 3 and 4)\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(vresprofiles_ws.iter_rows(min_row=8, min_col=4, max_col=4, values_only=True), start=8):\n",
    "    # Combine values from columns 3 and 4 to check for valid inflow identifiers\n",
    "    node = str(row[0]).strip().upper() if row[0] is not None else None\n",
    "    if node is None or node not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Remove duplicate row indices and sort them in reverse order to avoid shifting issues during deletion\n",
    "delete_rows = sorted(set(delete_rows))\n",
    "\n",
    "# Delete rows in reverse order to prevent issues with shifting after deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    vresprofiles_ws.delete_rows(row_idx) # Delete the rows\n",
    "\n",
    "# Save and close the updated Power_VRESProfiles.xlsx with the filtered data\n",
    "vresprofiles_wb.save(file_VRESProfiles)\n",
    "vresprofiles_wb.close()\n",
    "\n",
    "print(\"Power VRES Profiles data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Copy remaining files\n",
    "Copies all necessary remaining files required by LEGO that do not need modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination folder paths for file transfer\n",
    "source_folder = template_dir\n",
    "destination_folder = destination_dir\n",
    "\n",
    "# Loop through all files in the source folder\n",
    "for filename in os.listdir(source_folder):\n",
    "    # Ignore temp Excel files (e.g., ~$filename.xlsx)\n",
    "    if filename.startswith(\"~$\"):\n",
    "        print(f\"Skipped temp file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Clean filename just in case (strip whitespace)\n",
    "    filename_clean = filename.strip()\n",
    "\n",
    "    # Define full file paths\n",
    "    src_file = os.path.join(source_folder, filename_clean)\n",
    "    dest_file = os.path.join(destination_folder, filename_clean)\n",
    "\n",
    "    # Check if the source is a real file and the destination does not exist\n",
    "    if os.path.isfile(src_file) and not os.path.exists(dest_file):\n",
    "        shutil.copy2(src_file, dest_file)\n",
    "        print(f\"Copied: {filename_clean}\")\n",
    "    else:\n",
    "        print(f\"Skipped: {filename_clean} (already exists or not a file)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
