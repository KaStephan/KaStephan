{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TYNDP Translator\n",
    "\n",
    "Converts TYNDP data into the LEGO format. The TYNDP models future power grid requirements by representing bidding zones and their respective transport capacities.\n",
    "\n",
    "Figure 1 provides an overview of the bidding zone names.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"assets/Bidding_Zones.png\" alt=\"ENTSOE Bidding Zones\" width=\"500\"/>\n",
    "    <figcaption>Figure 1: Bidding Zones according to ENTSO-E.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:43: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:43: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:14: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  tyndp_dir = 'L:\\TYNDP 24\\Data'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:25: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2030_NT'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:27: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2030_DE'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:29: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2030_GA'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:34: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2040_NT'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:36: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2040_DE'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:38: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2040_GA'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:43: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2050_NT'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:45: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2050_DE'\n",
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_8488\\2814447418.py:47: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2050_GA'\n"
     ]
    }
   ],
   "source": [
    "## Paths\n",
    "import os\n",
    "\n",
    "# Simulation year (2030, 2040, 2050)\n",
    "simulation_year = 2030 \n",
    "\n",
    "# Scenario (National Trends, Distributed Energy, Global Ambition)\n",
    "scenario = 'National Trends' \n",
    "\n",
    "# Climate year (1982-2019). The three years by TYNDP2024: 1995, 2008, 2009. Standard: 2009\n",
    "cy_year = 2009\n",
    "\n",
    "# Path to TYNDP input data (Backup Available at Institutsdaten\\Daten\\TYNDP2024)\n",
    "tyndp_dir = 'L:\\TYNDP 24\\Data'\n",
    "\n",
    "# Path to template LEGO files (by default stored with script on GitHub)\n",
    "template_dir = 'LEGO_data_templates'\n",
    "\n",
    "# Path to pypsa data for electric line parameters\n",
    "pypsa_dir = 'PyPSA_Data'\n",
    "\n",
    "# Define destination folder where the results should be stored\n",
    "if simulation_year == 2030:\n",
    "    if scenario == 'National Trends':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2030_NT'\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2030_DE'\n",
    "    elif scenario == 'Global Ambition':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2030_GA'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2040:\n",
    "    if scenario == 'National Trends':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2040_NT'\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2040_DE'\n",
    "    elif scenario == 'Global Ambition':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2040_GA'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2050:\n",
    "    if scenario == 'National Trends':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2050_NT'\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2050_DE'\n",
    "    elif scenario == 'Global Ambition':\n",
    "        destination_dir = 'L:\\TYNDP 24\\Results\\V2G_2050_GA'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "\n",
    "\n",
    "## Other parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Pre-Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Destination directory already exists. Files may be overwritten.\n"
     ]
    }
   ],
   "source": [
    "# Ensure the destination directory exists\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "else:\n",
    "    print(\"Warning: Destination directory already exists. Files may be overwritten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check if a file is currently open\n",
    "def is_file_open(destination_file):\n",
    "    \"\"\"Check if a file is open by another application.\"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        try:\n",
    "            with open(destination_file, 'r+b') as file:\n",
    "                pass  # If successful, file is not open elsewhere\n",
    "            return False\n",
    "        except PermissionError:\n",
    "            return True\n",
    "    else:  # macOS/Linux\n",
    "        temp_file = os.path.join(os.path.dirname(destination_file), '~$' + os.path.basename(destination_file))\n",
    "        if os.path.exists(temp_file):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Copying files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Power_Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_Parameters.xlsx\n"
     ]
    }
   ],
   "source": [
    "# File paths for source data, template, and destination\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_parameters = os.path.join(template_dir, 'Power_Parameters.xlsx')\n",
    "destination_file_parameters = os.path.join(destination_dir, 'Power_Parameters.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_parameters):\n",
    "    if is_file_open(destination_file_parameters):\n",
    "        sys.exit(f\"File '{destination_file_parameters}' is currently open by another application.\")\n",
    "    os.remove(destination_file_parameters)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_parameters, destination_file_parameters)\n",
    "\n",
    "# Load relevant data from the source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Parameters\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Open the destination workbook and select the active worksheet\n",
    "destination_wb = load_workbook(destination_file_parameters)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Update specific cells in the destination file with values from the source data\n",
    "destination_ws.cell(row=5, column=3, value=df_other_sources.iloc[2,1])\n",
    "destination_ws.cell(row=56, column=3, value=df_other_sources.iloc[3,1])\n",
    "\n",
    "# Save and close the updated file\n",
    "destination_wb.save(destination_file_parameters)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"File saved successfully at: {destination_file_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Power_BusInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_BusInfo.xlsx\n"
     ]
    }
   ],
   "source": [
    "# File paths for source data, template, and destination\n",
    "source_file_businfo = os.path.join(tyndp_dir, 'Nodes/LIST OF NODES.xlsx')\n",
    "source_file_businfo_offshore = os.path.join(tyndp_dir, 'Line data/ReferenceGrid_Electricity.xlsx')\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_businfo = os.path.join(template_dir, 'Power_BusInfo.xlsx')\n",
    "destination_file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_businfo):\n",
    "    if is_file_open(destination_file_businfo):\n",
    "        sys.exit(f\"File '{destination_file_businfo}' is currently open by another application.\")\n",
    "    os.remove(destination_file_businfo)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_businfo, destination_file_businfo)\n",
    "\n",
    "# Load the destination workbook and select the first sheet\n",
    "destination_wb = load_workbook(destination_file_businfo)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Load and process (onshore) bus data\n",
    "df_source = pd.read_excel(source_file_businfo, usecols=[0], header=0)  # Read column A (bus names)\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_BusInfo\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Write onshore buses to the destination file, starting at row 7 in column B\n",
    "start_row = 7\n",
    "for i, value in enumerate(df_source.iloc[:, 0], start=start_row):\n",
    "    destination_ws[f'B{i}'] = value # Bus name\n",
    "    destination_ws[f'C{i}'] = f'Zon_{value}' # Zone name\n",
    "\n",
    "    # Assign static parameter values from df_other_sources\n",
    "    destination_ws[f'D{i}'] = df_other_sources.iloc[4, 1] # BasVolt\n",
    "    destination_ws[f'E{i}'] = df_other_sources.iloc[5, 1] # maxVolt\n",
    "    destination_ws[f'F{i}'] = df_other_sources.iloc[6, 1] # minVolt\n",
    "    destination_ws[f'G{i}'] = df_other_sources.iloc[7, 1] # Bs\n",
    "    destination_ws[f'H{i}'] = df_other_sources.iloc[8, 1] # Gs\n",
    "    destination_ws[f'I{i}'] = df_other_sources.iloc[9, 1] # PowerFactor\n",
    "    if df_other_sources.iloc[10, 1] != \"\":\n",
    "        destination_ws[f'J{i}'] = df_other_sources.iloc[10, 1] # YearCom\n",
    "    if df_other_sources.iloc[11, 1] != \"\":\n",
    "        destination_ws[f'K{i}'] = df_other_sources.iloc[11, 1] # YearDecom\n",
    "    if df_other_sources.iloc[12, 1] != \"\":\n",
    "        destination_ws[f'L{i}'] = df_other_sources.iloc[12, 1] # lat\n",
    "    if df_other_sources.iloc[13, 1] != \"\":\n",
    "        destination_ws[f'M{i}'] = df_other_sources.iloc[12, 1] # lon\n",
    "\n",
    "# Load and process offshore bus data\n",
    "df_source_offshore = pd.read_excel(source_file_businfo_offshore, sheet_name=\"Offshore (for info)\", usecols=[0], header=0)\n",
    "\n",
    "# Extract offshore bus names and split ranges (e.g., \"AL00-BA00\" â†’ \"AL00\", \"BA00\")\n",
    "bus_list = []\n",
    "for entry in df_source_offshore.iloc[:, 0].dropna().astype(str):\n",
    "    bus_list.extend(entry.split('-'))\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "bus_list = list(dict.fromkeys(bus_list))\n",
    "\n",
    "# Get the list of existing onshore buses\n",
    "existing_buses = set(df_source.iloc[:, 0].dropna())\n",
    "\n",
    "# Identify offshore buses that are not already in column B\n",
    "new_buses = [bus for bus in bus_list if bus not in existing_buses]   \n",
    "\n",
    "# Append new offshore buses to the destination file\n",
    "if new_buses:\n",
    "    for i, value in enumerate(new_buses, start=len(existing_buses) + start_row):\n",
    "        destination_ws[f'B{i}'] = value # Bus name\n",
    "        destination_ws[f'C{i}'] = f'Zon_{value}' # Zone name\n",
    "\n",
    "        # Assign static parameter values from df_other_sources\n",
    "        destination_ws[f'D{i}'] = df_other_sources.iloc[4, 1] # BasVolt\n",
    "        destination_ws[f'E{i}'] = df_other_sources.iloc[5, 1] # maxVolt\n",
    "        destination_ws[f'F{i}'] = df_other_sources.iloc[6, 1] # minVolt\n",
    "        destination_ws[f'G{i}'] = df_other_sources.iloc[7, 1] # Bs\n",
    "        destination_ws[f'H{i}'] = df_other_sources.iloc[8, 1] # Gs\n",
    "        destination_ws[f'I{i}'] = df_other_sources.iloc[9, 1] # PowerFactor\n",
    "        if df_other_sources.iloc[10, 1] != \"\":\n",
    "            destination_ws[f'J{i}'] = df_other_sources.iloc[10, 1] # YearCom\n",
    "        if df_other_sources.iloc[11, 1] != \"\":\n",
    "            destination_ws[f'K{i}'] = df_other_sources.iloc[11, 1] # YearDecom\n",
    "        if df_other_sources.iloc[12, 1] != \"\":\n",
    "            destination_ws[f'L{i}'] = df_other_sources.iloc[12, 1] # lat\n",
    "        if df_other_sources.iloc[13, 1] != \"\":\n",
    "            destination_ws[f'M{i}'] = df_other_sources.iloc[12, 1] # lon\n",
    "\n",
    "# Save and close the updated destination file\n",
    "destination_wb.save(destination_file_businfo)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"File saved successfully at: {destination_file_businfo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Power_Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copying demand for AL00.\n",
      "Year 2009 not found in sheet AL00. Skipping node.\n",
      "Start copying demand for AT00.\n",
      "Year 2009 not found in sheet AT00. Skipping node.\n",
      "Start copying demand for BA00.\n",
      "Year 2009 not found in sheet BA00. Skipping node.\n",
      "Start copying demand for BE00.\n",
      "Year 2009 not found in sheet BE00. Skipping node.\n",
      "Start copying demand for BG00.\n",
      "Year 2009 not found in sheet BG00. Skipping node.\n",
      "Start copying demand for CH00.\n",
      "Year 2009 not found in sheet CH00. Skipping node.\n",
      "Start copying demand for CY00.\n",
      "Year 2009 not found in sheet CY00. Skipping node.\n",
      "Start copying demand for CZ00.\n",
      "Year 2009 not found in sheet CZ00. Skipping node.\n",
      "Start copying demand for DE00.\n",
      "Year 2009 not found in sheet DE00. Skipping node.\n",
      "Start copying demand for DKE1.\n",
      "Year 2009 not found in sheet DKE1. Skipping node.\n",
      "Start copying demand for DZ00.\n",
      "Year 2009 not found in sheet DZ00. Skipping node.\n",
      "Start copying demand for DKW1.\n",
      "Year 2009 not found in sheet DKW1. Skipping node.\n",
      "Start copying demand for EE00.\n",
      "Year 2009 not found in sheet EE00. Skipping node.\n",
      "Start copying demand for EG00.\n",
      "Year 2009 not found in sheet EG00. Skipping node.\n",
      "Start copying demand for ES00.\n",
      "Year 2009 not found in sheet ES00. Skipping node.\n",
      "Start copying demand for FI00.\n",
      "Year 2009 not found in sheet FI00. Skipping node.\n",
      "Start copying demand for FR00.\n",
      "Year 2009 not found in sheet FR00. Skipping node.\n",
      "Start copying demand for FR15.\n",
      "Year 2009 not found in sheet FR15. Skipping node.\n",
      "Start copying demand for GE00.\n",
      "Year 2009 not found in sheet GE00. Skipping node.\n",
      "Start copying demand for GR00.\n",
      "Year 2009 not found in sheet GR00. Skipping node.\n",
      "Start copying demand for GR03.\n",
      "Year 2009 not found in sheet GR03. Skipping node.\n",
      "Start copying demand for HR00.\n",
      "Year 2009 not found in sheet HR00. Skipping node.\n",
      "Start copying demand for HU00.\n",
      "Year 2009 not found in sheet HU00. Skipping node.\n",
      "Start copying demand for IL00.\n",
      "Year 2009 not found in sheet IL00. Skipping node.\n",
      "Start copying demand for IE00.\n",
      "Year 2009 not found in sheet IE00. Skipping node.\n",
      "Start copying demand for ITCA.\n",
      "Year 2009 not found in sheet ITCA. Skipping node.\n",
      "Start copying demand for ITCN.\n",
      "Year 2009 not found in sheet ITCN. Skipping node.\n",
      "Start copying demand for ITCS.\n",
      "Year 2009 not found in sheet ITCS. Skipping node.\n",
      "Start copying demand for ITN1.\n",
      "Year 2009 not found in sheet ITN1. Skipping node.\n",
      "Start copying demand for ITS1.\n",
      "Year 2009 not found in sheet ITS1. Skipping node.\n",
      "Start copying demand for ITSA.\n",
      "Year 2009 not found in sheet ITSA. Skipping node.\n",
      "Start copying demand for ITSI.\n",
      "Year 2009 not found in sheet ITSI. Skipping node.\n",
      "Start copying demand for LT00.\n",
      "Year 2009 not found in sheet LT00. Skipping node.\n",
      "Start copying demand for LUB1.\n",
      "Year 2009 not found in sheet LUB1. Skipping node.\n",
      "Start copying demand for LUF1.\n",
      "Year 2009 not found in sheet LUF1. Skipping node.\n",
      "Start copying demand for LUG1.\n",
      "Year 2009 not found in sheet LUG1. Skipping node.\n",
      "Start copying demand for LY00.\n",
      "Year 2009 not found in sheet LY00. Skipping node.\n",
      "Start copying demand for MD00.\n",
      "Year 2009 not found in sheet MD00. Skipping node.\n",
      "Start copying demand for MA00.\n",
      "Year 2009 not found in sheet MA00. Skipping node.\n",
      "Start copying demand for LV00.\n",
      "Year 2009 not found in sheet LV00. Skipping node.\n",
      "Start copying demand for ME00.\n",
      "Year 2009 not found in sheet ME00. Skipping node.\n",
      "Start copying demand for MK00.\n",
      "Year 2009 not found in sheet MK00. Skipping node.\n",
      "Start copying demand for MT00.\n",
      "Year 2009 not found in sheet MT00. Skipping node.\n",
      "Start copying demand for NL00.\n",
      "Year 2009 not found in sheet NL00. Skipping node.\n",
      "Start copying demand for NOM1.\n",
      "Year 2009 not found in sheet NOM1. Skipping node.\n",
      "Start copying demand for NON1.\n",
      "Year 2009 not found in sheet NON1. Skipping node.\n",
      "Start copying demand for NOS0.\n",
      "Year 2009 not found in sheet NOS0. Skipping node.\n",
      "Start copying demand for PL00.\n",
      "Year 2009 not found in sheet PL00. Skipping node.\n",
      "Start copying demand for PS00.\n",
      "Year 2009 not found in sheet PS00. Skipping node.\n",
      "Start copying demand for PT00.\n",
      "Year 2009 not found in sheet PT00. Skipping node.\n",
      "Start copying demand for RO00.\n",
      "Year 2009 not found in sheet RO00. Skipping node.\n",
      "Start copying demand for RS00.\n",
      "Year 2009 not found in sheet RS00. Skipping node.\n",
      "Start copying demand for SE01.\n",
      "Year 2009 not found in sheet SE01. Skipping node.\n",
      "Start copying demand for SE02.\n",
      "Year 2009 not found in sheet SE02. Skipping node.\n",
      "Start copying demand for SE03.\n",
      "Year 2009 not found in sheet SE03. Skipping node.\n",
      "Start copying demand for SE04.\n",
      "Year 2009 not found in sheet SE04. Skipping node.\n",
      "Start copying demand for SI00.\n",
      "Year 2009 not found in sheet SI00. Skipping node.\n",
      "Start copying demand for SK00.\n",
      "Year 2009 not found in sheet SK00. Skipping node.\n",
      "Start copying demand for TN00.\n",
      "Year 2009 not found in sheet TN00. Skipping node.\n",
      "Start copying demand for TR00.\n",
      "Year 2009 not found in sheet TR00. Skipping node.\n",
      "Start copying demand for UA00.\n",
      "Year 2009 not found in sheet UA00. Skipping node.\n",
      "Start copying demand for UK00.\n",
      "Year 2009 not found in sheet UK00. Skipping node.\n",
      "Start copying demand for UKNI.\n",
      "Year 2009 not found in sheet UKNI. Skipping node.\n",
      "Data saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_Demand.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source data, template, and destination\n",
    "if simulation_year == 2030:\n",
    "    if scenario == 'National Trends':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/NT/Electricity demand profiles/2030_National Trends.xlsx')\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/DE/2030/ELECTRICITY_MARKET DE 2030.xlsx')\n",
    "    elif scenario == 'Global Ambition':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/GA/2030/ELECTRICITY_MARKET GA 2030.xlsx')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2040:\n",
    "    if scenario == 'National Trends':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/NT/Electricity demand profiles/2040_National Trends.xlsx')\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/DE/2040/ELECTRICITY_MARKET DE 2040.xlsx')\n",
    "    elif scenario == 'Global Ambition':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/GA/2030/ELECTRICITY_MARKET GA 2040.xlsx')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "elif simulation_year == 2050:\n",
    "    if scenario == 'National Trends':\n",
    "        raise ValueError(\"National Trends scenario is not available for 2050.\")\n",
    "    elif scenario == 'Distributed Energy':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/DE/2050/ELECTRICITY_MARKET DE 2050.xlsx')\n",
    "    elif scenario == 'Global Ambition':\n",
    "        source_file_demand_profiles = os.path.join(tyndp_dir, 'Demand Profiles/GA/2050/ELECTRICITY_MARKET GA 2050.xlsx')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scenario. Please choose 'National Trends', 'Distributed Energy', or 'Global Ambition'.\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_demand = os.path.join(template_dir, 'Power_Demand.xlsx')\n",
    "destination_file_demand = os.path.join(destination_dir, 'Power_Demand.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_demand):\n",
    "    if is_file_open(destination_file_demand):\n",
    "        sys.exit(f\"File '{destination_file_demand}' is currently open by another application.\")\n",
    "    os.remove(destination_file_demand)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_demand, destination_file_demand)\n",
    "\n",
    "# Validate that the selected year is within the supported range\n",
    "if cy_year < 1982 or cy_year > 2019:\n",
    "    raise ValueError(\"Year must be between 1982 and 2019.\")\n",
    "\n",
    "# Load the demand profiles Excel file (containing multiple sheets for different nodes)\n",
    "demand_profiles_wb = pd.ExcelFile(source_file_demand_profiles)\n",
    "\n",
    "# Load additional parameters from another source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Demand\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Load the destination workbook where the data will be written\n",
    "destination_wb = load_workbook(destination_file_demand)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Define the starting row in the destination file for writing demand profiles\n",
    "row_start = 7\n",
    "\n",
    "# Process each worksheet (node) in the demand profiles file\n",
    "for sheet_name in demand_profiles_wb.sheet_names:\n",
    "    print(f\"Start copying demand for {sheet_name}.\")\n",
    "    \n",
    "    # Load the time-series data for the node, skipping metadata rows\n",
    "    node_df = demand_profiles_wb.parse(sheet_name, skiprows=11, nrows=8760)\n",
    "\n",
    "    # Identify year columns (assuming data for 1982-2019 starts from column E)\n",
    "    year_columns = node_df.columns[4:len(node_df.columns)]\n",
    "    \n",
    "    # Check if the selected year is available in the dataset\n",
    "    if cy_year not in year_columns:\n",
    "        print(f\"Year {cy_year} not found in sheet {sheet_name}. Skipping node.\")\n",
    "        continue\n",
    "    \n",
    "    # Get the column index corresponding to the selected year\n",
    "    year_col_idx = year_columns.get_loc(cy_year) + 4  # Convert relative index to absolute column index\n",
    "\n",
    "    # Extract the hourly demand time series for the selected year\n",
    "    time_series = node_df.iloc[:, year_col_idx]\n",
    "\n",
    "    # Write periode and node name value to the destination file\n",
    "    destination_ws[f'B{row_start}'] = df_other_sources.iloc[2, 1] # Periode\n",
    "    destination_ws[f'C{row_start}'] = sheet_name # Node name\n",
    "\n",
    "    # Write the demand values (8760 hours) into the corresponding row, starting from column E\n",
    "    for i, demand in enumerate(time_series, start=4):\n",
    "        destination_ws.cell(row=row_start, column=i, value=round(demand,2))\n",
    "    \n",
    "    # Move to the next row for the next node\n",
    "    row_start += 1\n",
    "\n",
    "# Save and close the modified workbook to the destination file\n",
    "destination_wb.save(destination_file_demand)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_demand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Power_Inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_AL00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_AT00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_BA00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_BE00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_BG00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_CH00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_CZ00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_DE00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ES00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_FI00_Hydro_Inflows_2030.xlsx\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_FR00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_GR00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_HR00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_HU00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_IE00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITCA_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITCN_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITCS_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITN1_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITS1_Hydro_Inflows_2030.xlsx\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITSA_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ITSI_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_LT00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_LUG1_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_LUV1_Hydro_Inflows_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_LV00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_ME00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_MK00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_NL00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_NOM1_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_NON1_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_NOS0_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_PL00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_PT00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_RO00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_RS00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_SE01_Hydro_Inflows_2030.xlsx\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_SE02_Hydro_Inflows_2030.xlsx\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_SE03_Hydro_Inflows_2030.xlsx\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_SE04_Hydro_Inflows_2030.xlsx\n",
      "Writing HS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_SI00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_SK00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Writing HS data...\n",
      "Writing HPS data...\n",
      "L:\\TYNDP 24\\Data\\Hydro Inflows/2030\\PEMMDB_UK00_Hydro_Inflows_2030.xlsx\n",
      "Writing ROR data...\n",
      "Data saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_Inflows.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source data, template, and destination\n",
    "if simulation_year == 2030:\n",
    "    folder_source_files_inflows = os.path.join(tyndp_dir, 'Hydro Inflows/2030')\n",
    "elif simulation_year == 2040:\n",
    "    folder_source_files_inflows = os.path.join(tyndp_dir, 'Hydro Inflows/2040')\n",
    "elif simulation_year == 2050:\n",
    "    folder_source_files_inflows = os.path.join(tyndp_dir, 'Hydro Inflows/2050')\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_inflows = os.path.join(template_dir, 'Power_Inflows.xlsx')\n",
    "destination_file_inflows = os.path.join(destination_dir, 'Power_Inflows.xlsx')\n",
    "\n",
    "# Remove the existing destination file if it exists to ensure a clean start\n",
    "if os.path.exists(destination_file_inflows):\n",
    "    if is_file_open(destination_file_inflows):\n",
    "        sys.exit(f\"File '{destination_file_inflows}' is currently open by another application.\")\n",
    "    os.remove(destination_file_inflows)\n",
    "\n",
    "# Copy the template file to the destination as a base for modifications\n",
    "shutil.copy(template_file_inflows, destination_file_inflows)\n",
    "\n",
    "# Load additional parameters from another source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Inflows\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Load the destination workbook where the processed data will be stored\n",
    "destination_wb = load_workbook(destination_file_inflows)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Retrieve all relevant inflow data files from the specified folder\n",
    "inflows_files = sorted(f for f in os.listdir(folder_source_files_inflows) if (f.startswith(\"PEMMDB\") and f.endswith(\".xlsx\")))\n",
    "\n",
    "# Define the starting row in the destination file for writing network data\n",
    "row_start = 7\n",
    "\n",
    "# Process each inflow file\n",
    "for filename in inflows_files:\n",
    "    file_path = os.path.join(folder_source_files_inflows, filename)  # Construct full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a file\n",
    "\n",
    "        # Load the inflows Excel file\n",
    "        inflows_wb = pd.ExcelFile(file_path)\n",
    "        print(file_path)\n",
    "\n",
    "        # Load different types of inflow data from the workbook\n",
    "        ror_df = inflows_wb.parse('Run of River - Year Dependent', skiprows=1, nrows=365)\n",
    "        pondage_df = inflows_wb.parse('Pondage - Year Dependent', skiprows=1, nrows=365)\n",
    "        hs_df = inflows_wb.parse('Reservoir - Year Dependent', skiprows=1, nrows=53)\n",
    "        hps_df = inflows_wb.parse('PS Open - Year Dependent', skiprows=1, nrows=53)\n",
    "        hcps_df = inflows_wb.parse('PS Closed - Year Dependent', skiprows=1, nrows=53)\n",
    "\n",
    "        # Identify year columns (assuming data for 1982-2019 starts from column D)\n",
    "        year_columns = ror_df.columns[3:]\n",
    "        \n",
    "        # Check if the selected year is available in the dataset\n",
    "        if cy_year not in year_columns:\n",
    "            print(f\"Year {cy_year} not found in sheet {filename}. Skipping node.\")\n",
    "            continue\n",
    "\n",
    "        # Get the column index corresponding to the selected year\n",
    "        year_col_idx = year_columns.get_loc(cy_year) + 3  # Adjust index to match actual column position\n",
    "\n",
    "        # Extract the inflow time series for the selected year, replacing NaNs with zeros\n",
    "        time_series_ror = ror_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_pondage = pondage_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_hs = hs_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_hps = hps_df.iloc[:, year_col_idx].fillna(0)\n",
    "        time_series_hcps = hcps_df.iloc[:, year_col_idx].fillna(0)\n",
    "\n",
    "        # Combine Run-of-River (ROR) and Pondage inflow data\n",
    "        time_series_ror_pondage = time_series_ror + time_series_pondage\n",
    "\n",
    "        # Define inflow categories and their respective time series\n",
    "        inflow_categories = {\n",
    "            'ROR': time_series_ror_pondage,\n",
    "            'HS': time_series_hs,\n",
    "            'HPS': time_series_hps,\n",
    "            'HCPS': time_series_hcps\n",
    "        }\n",
    "\n",
    "        # Process and write data for each inflow category\n",
    "        for inflow_type, series in inflow_categories.items():\n",
    "            if series.sum() == 0:  # Skip writing if the entire time series is zero\n",
    "                continue\n",
    "\n",
    "            # Write periode and power plant name value to the destination file\n",
    "            destination_ws[f'B{row_start}'] = df_other_sources.iloc[2, 1] # Periode\n",
    "            destination_ws[f'C{row_start}'] = filename.split('_')[1] + inflow_type # Power plant name\n",
    "            print(f\"Writing {inflow_type} data...\")\n",
    "\n",
    "            # Define the starting column in the destination file for writing inflows\n",
    "            column_start = 4\n",
    "\n",
    "            # RoR inflows are provided as a daily profile\n",
    "            if inflow_type == 'ROR':\n",
    "                # Distribute daily inflows evenly across 24 hours\n",
    "                for inflow in series:  \n",
    "                    for h in range(24):  # Repeat for each hour of the day\n",
    "                        destination_ws.cell(row=row_start, column=column_start, value=round(inflow*1000 / 24,4))\n",
    "                        column_start += 1\n",
    "            \n",
    "            # HS, HPS and HS inflows are provided as weekly profiles\n",
    "            elif inflow_type in ['HS', 'HPS', 'HCPS']:\n",
    "                hour_count = 0  # Counter to track written hours\n",
    "                previous_inflow = 0 # Store previous week's inflow value\n",
    "                \n",
    "                for inflow in series:\n",
    "                    for h in range(7 * 24):  # Distribute weekly inflows across 7 days (168 hours)\n",
    "                        if hour_count >= 8760:  # Stop once reaching 8760 hours\n",
    "                            break\n",
    "\n",
    "                        # If in the last week and inflow is missing, use previous week's value\n",
    "                        if hour_count >= 8736 and inflow == 0:\n",
    "                            inflow = previous_inflow if previous_inflow is not None else 0\n",
    "                        \n",
    "                        # Write the inflow value to the corresponding cell\n",
    "                        destination_ws.cell(row=row_start, column=column_start, value=round(inflow*1000 / (7 * 24),4))\n",
    "                        \n",
    "                        previous_inflow = inflow # Store current inflow as reference for next iteration\n",
    "                        column_start += 1\n",
    "                        hour_count += 1\n",
    "\n",
    "                    if hour_count >= 8760:  # Stop processing once 8760 hours are written\n",
    "                        break\n",
    "        \n",
    "            # Move to the next row for the next inflow category\n",
    "            row_start += 1\n",
    "\n",
    "# Save and close the modified workbook to the destination file\n",
    "destination_wb.save(destination_file_inflows)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_inflows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Power_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_Network.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source data, template, and destination file\n",
    "source_file_network = os.path.join(tyndp_dir, 'Line data/ReferenceGrid_Electricity.xlsx')\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "template_file_network = os.path.join(template_dir, 'Power_Network.xlsx')\n",
    "destination_file_network = os.path.join(destination_dir, 'Power_Network.xlsx')\n",
    "\n",
    "# If the destination file exists, remove it to ensure a clean start\n",
    "if os.path.exists(destination_file_network):\n",
    "    if is_file_open(destination_file_network):\n",
    "        sys.exit(f\"File '{destination_file_network}' is currently open by another application.\")\n",
    "    os.remove(destination_file_network)\n",
    "\n",
    "# Copy the template file to the destination for modification\n",
    "shutil.copy(template_file_network, destination_file_network)\n",
    "\n",
    "# Load the destination workbook and select the active worksheet\n",
    "destination_wb = load_workbook(destination_file_network)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Load onshore transmission network data\n",
    "df_source = pd.read_excel(source_file_network, usecols=[0,1,2], header=0, sheet_name=\"2030\")  # Read column A\n",
    "\n",
    "# Load additional parameters from another source file\n",
    "df_other_sources = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Network\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Replace column 1 values with the maximum of column 1 and column 2 to get the max transport capacity\n",
    "df_source.iloc[:, 1] = df_source.iloc[:, 1].combine(df_source.iloc[:, 2], max)\n",
    "\n",
    "# Remove column C as it's no longer needed\n",
    "df_source.drop(df_source.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Keep only rows where the transmission capacity (column B) is non-zero\n",
    "df_source = df_source[df_source.iloc[:, 1] != 0]\n",
    "\n",
    "# Define the starting row in the destination file for writing NTC data\n",
    "start_row = 7\n",
    "\n",
    "# Write processed onshore network data to the destination file\n",
    "for i, value in enumerate(df_source.iloc[:, 0], start=start_row):\n",
    "    destination_ws[f'B{i}'] = value.split('-')[0]  # Bus from name in column B\n",
    "    destination_ws[f'C{i}'] = value.split('-')[1]  # Bus to name in column C\n",
    "\n",
    "    # Assign predefined static values from the other sources file\n",
    "    destination_ws[f'D{i}'] = df_other_sources.iloc[4, 1] # Circuit\n",
    "    destination_ws[f'E{i}'] = df_other_sources.iloc[5, 1] # InService\n",
    "    destination_ws[f'I{i}'] = df_other_sources.iloc[9, 1] # TapAngle\n",
    "    destination_ws[f'J{i}'] = df_other_sources.iloc[10, 1] # TapRatio\n",
    "    destination_ws[f'K{i}'] = df_source.iloc[i-start_row, 1] # Pmax\n",
    "\n",
    "# Save the modified workbook\n",
    "destination_wb.save(destination_file_network)\n",
    "\n",
    "# Load offshore transmission network data\n",
    "df_source_offshore = pd.read_excel(source_file_network, usecols=[0,1,2], header=0, sheet_name=\"Offshore (for info)\")  # Read column A\n",
    "\n",
    "# Replace column 1 values with the maximum of column 1 and column 2 to get the max transport capacity\n",
    "df_source_offshore.iloc[:, 1] = df_source_offshore.iloc[:, 1].combine(df_source_offshore.iloc[:, 2], max)\n",
    "\n",
    "# Remove column C as it's no longer needed\n",
    "df_source_offshore.drop(df_source_offshore.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Keep only rows where the transmission capacity (column B) is non-zero\n",
    "df_source_offshore = df_source_offshore[df_source_offshore.iloc[:, 1] != 0]\n",
    "\n",
    "# Write processed offshore network data to the destination file\n",
    "for i, value in enumerate(df_source_offshore.iloc[:, 0], start=len(df_source) + start_row):\n",
    "    destination_ws[f'B{i}'] = value.split('-')[0]  # Bus from name in column B\n",
    "    destination_ws[f'C{i}'] = value.split('-')[1]  # Bus to name in column C\n",
    "\n",
    "    # Assign predefined static values from the other sources file\n",
    "    destination_ws[f'D{i}'] = df_other_sources.iloc[4, 1] # Circuit\n",
    "    destination_ws[f'E{i}'] = df_other_sources.iloc[5, 1] # InService\n",
    "    destination_ws[f'I{i}'] = df_other_sources.iloc[9, 1] # TapAngle\n",
    "    destination_ws[f'J{i}'] = df_other_sources.iloc[10, 1] # TapRatio\n",
    "    destination_ws[f'K{i}'] = df_source_offshore.iloc[i-start_row-len(df_source), 1] # Pmax\n",
    "\n",
    "# Save and close the final modified workbook\n",
    "destination_wb.save(destination_file_network)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_network}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Power_NTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_NTC.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source data, template, and destination file\n",
    "source_file_ntc = os.path.join(tyndp_dir, 'Line data/ReferenceGrid_Electricity.xlsx')\n",
    "template_file_ntc = os.path.join(template_dir, 'Power_NTC.xlsx')\n",
    "destination_file_ntc = os.path.join(destination_dir, 'Power_NTC.xlsx')\n",
    "\n",
    "# If the destination file exists, remove it to ensure a clean start\n",
    "if os.path.exists(destination_file_ntc):\n",
    "    if is_file_open(destination_file_ntc):\n",
    "        sys.exit(f\"File '{destination_file_ntc}' is currently open by another application.\")\n",
    "    os.remove(destination_file_ntc)\n",
    "\n",
    "# Copy the template file to the destination for modification\n",
    "shutil.copy(template_file_ntc, destination_file_ntc)\n",
    "\n",
    "# Load the destination workbook and select the active worksheet\n",
    "destination_wb = load_workbook(destination_file_ntc)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Load and process onshore transmission network data\n",
    "df_source = pd.read_excel(source_file_ntc, usecols=[0,1,2], header=0, sheet_name=\"2030\")  # Read column A\n",
    "\n",
    "# Keep only the rows where both columns B and C are not zero\n",
    "df_source = df_source[~((df_source.iloc[:, 1] == 0) & (df_source.iloc[:, 2] == 0))]\n",
    "\n",
    "# Define the starting row in the destination file for writing inflow data\n",
    "start_row = 7\n",
    "\n",
    "# Write the processed onshore network data to the destination file\n",
    "for i, value in enumerate(df_source.iloc[:, 0], start=start_row):\n",
    "    # Assign 'from' and 'to' zone names, and their respective transmission capacities\n",
    "    destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[0]  # FromZone\n",
    "    destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[1]  # ToZone\n",
    "    destination_ws[f'D{i}'] = df_source.iloc[i-start_row, 1] # Pmax\n",
    "\n",
    "# Write the reverse direction (from 'to' to 'from') with respective transmission capacities\n",
    "for i, value in enumerate(df_source.iloc[:, 0], start=len(df_source) + start_row):\n",
    "    destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[1]  # FromZone\n",
    "    destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[0]  # ToZone\n",
    "    destination_ws[f'D{i}'] = df_source.iloc[i-start_row-len(df_source) , 2] # Pmax\n",
    "\n",
    "\n",
    "# Save the modified workbook to the destination\n",
    "destination_wb.save(destination_file_ntc)\n",
    "\n",
    "# Load and process offshore transmission network data\n",
    "df_source_offshore = pd.read_excel(source_file_ntc, usecols=[0,1,2], header=0, sheet_name=\"Offshore (for info)\")  # Read column A\n",
    "\n",
    "# Keep only the rows where both columns B and C are not zero\n",
    "df_source_offshore = df_source_offshore[~((df_source_offshore.iloc[:, 1] == 0) & (df_source_offshore.iloc[:, 2] == 0))]\n",
    "\n",
    "# Write the processed offshore network data to the destination file\n",
    "for i, value in enumerate(df_source_offshore.iloc[:, 0], start=2*len(df_source) + start_row):\n",
    "    # Assign 'from' and 'to' zone names, and their respective transmission capacities\n",
    "    destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[0]  # FromZone\n",
    "    destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[1]  # ToZone\n",
    "    destination_ws[f'D{i}'] = df_source_offshore.iloc[i-start_row-2*len(df_source), 1] # Pmax\n",
    "\n",
    "# Write the reverse direction (from 'to' to 'from') with respective transmission capacities\n",
    "for i, value in enumerate(df_source_offshore.iloc[:, 0], start=2*len(df_source) + len(df_source_offshore) + start_row):\n",
    "    destination_ws[f'B{i}'] = 'Zon_' + value.split('-')[1]  # FromZone\n",
    "    destination_ws[f'C{i}'] = 'Zon_' + value.split('-')[0]  # ToZone\n",
    "    destination_ws[f'D{i}'] = df_source_offshore.iloc[i-start_row-2*len(df_source)-len(df_source_offshore), 2] # Pmax\n",
    "\n",
    "# Save and close the final modified workbook to the destination\n",
    "destination_wb.save(destination_file_ntc)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_ntc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Power_RoR, Power_Storage, Power_VRES & Power_ThermalGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_AL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_AT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_BA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_BE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_BEOF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_BG00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_CH00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_CY00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_CZ00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DEKF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DKBH_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DKE1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DKKF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DKNS_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DKW1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_DZ00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_EE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_EEOF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_EG00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ES00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_FI00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_FR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_FR15_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_GE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_GR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_GR03_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_HR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_HU00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_IE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_IL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITCA_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITCN_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITCS_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITN1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITS1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITSA_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ITSI_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LTOF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LUB1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LUF1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LUG1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LUV1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LV00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_LY00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_MA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_MD00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_ME00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_MK00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_MT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NL60_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NL6H_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NLA0_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NLBH_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NLLL_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NOM1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NON1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_NOS0_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_PL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_PS00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_PT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_RO00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_RS00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_SE01_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_SE02_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_SE03_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_SE04_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_SI00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_SK00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_TN00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_TR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_UA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_UK00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030/PEMMDB_UKNI_NationalTrends_2030.xlsx\n",
      "Generator data saved successfully copied.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source data, template files, and destination files\n",
    "if simulation_year == 2030:\n",
    "    folder_source_files_generators = os.path.join(tyndp_dir, 'PEMMDB2/2030/')\n",
    "elif simulation_year == 2040:\n",
    "    folder_source_files_generators = os.path.join(tyndp_dir, 'PEMMDB2/2040/')   \n",
    "elif simulation_year == 2050:\n",
    "    folder_source_files_generators = os.path.join(tyndp_dir, 'PEMMDB2/2050/')\n",
    "else:\n",
    "    raise ValueError(\"Unsupported simulation year. Please choose 2030, 2040, or 2050.\")\n",
    "\n",
    "source_file_other_sources = os.path.join(tyndp_dir, 'Sources_and_other_data.xlsx')\n",
    "source_file_prices = os.path.join(tyndp_dir, 'Prices/2023 06 22 TYNDP 2024 Commodity prices Final.xlsx')\n",
    "\n",
    "# Define template and destination file mappings for different power generation types\n",
    "files = {\n",
    "    \"RoR\": (os.path.join(template_dir, 'Power_RoR.xlsx'), os.path.join(destination_dir, 'Power_RoR.xlsx')),\n",
    "    \"Storage\": (os.path.join(template_dir, 'Power_Storage.xlsx'), os.path.join(destination_dir, 'Power_Storage.xlsx')),\n",
    "    \"VRES\": (os.path.join(template_dir, 'Power_VRES.xlsx'), os.path.join(destination_dir, 'Power_VRES.xlsx')),\n",
    "    \"Thermal\": (os.path.join(template_dir, 'Power_ThermalGen.xlsx'), os.path.join(destination_dir, 'Power_ThermalGen.xlsx')),\n",
    "}\n",
    "\n",
    "# Load price data from the source Excel file\n",
    "df_prices = pd.read_excel(source_file_prices, sheet_name=\"Matrix 2024\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Load data for various power generation sources\n",
    "df_other_sources_RoR = pd.read_excel(source_file_other_sources, sheet_name=\"Power_RoR\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_HS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_HS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_HPS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_HPS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_HPSCL = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_HPSCL\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Storage_BESS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Storage_BESS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_Wind = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_Wind\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_WindOff = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_WindOff\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_PV = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_PV\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_CSP = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_CSP\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_VRES_OtherRES = pd.read_excel(source_file_other_sources, sheet_name=\"Power_VRES_OtherRES\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_Nuclear = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_Nuclear\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_CoalCCS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_CoalCCS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LigniteCCS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LigniteCCS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasConvOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasConvOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasConvOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasConvOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTCCS = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTCCS\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasOCGTOld = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasOCGTOld\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasOCGTNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasOCGTNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_LightOil = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_LightOil\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_HeavyOilOld1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_HeavyOilOld1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_HeavyOilOld2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_HeavyOilOld2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_OilShaleOld = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_OilShaleOld\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_OilShaleNew = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_OilShaleNew\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTPresent1 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTPresent1\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_GasCCGTPresent2 = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_GasCCGTPresent2\", usecols=[1,2,3], header=0)\n",
    "df_other_sources_Thermal_OtherNonRES = pd.read_excel(source_file_other_sources, sheet_name=\"Power_Thermal_OtherNonRES\", usecols=[1,2,3], header=0)\n",
    "\n",
    "# Dictionary to store loaded workbooks and worksheets\n",
    "workbooks = {}\n",
    "worksheets = {}\n",
    "\n",
    "# Iterate through each power generation type and prepare destination files\n",
    "for key, (template_file, destination_file) in files.items():\n",
    "    # If the destination file already exists, remove it to start fresh\n",
    "    if os.path.exists(destination_file):\n",
    "        if is_file_open(destination_file):\n",
    "            sys.exit(f\"File '{destination_file}' is currently open by another application.\")\n",
    "        os.remove(destination_file)\n",
    "\n",
    "    # Copy the template file to the destination\n",
    "    shutil.copy(template_file, destination_file)\n",
    "\n",
    "    # Load the copied file as a workbook and select the active worksheet\n",
    "    destination_wb = load_workbook(destination_file)\n",
    "    destination_ws = destination_wb.active\n",
    "\n",
    "    # Store the workbook and worksheet in the dictionaries for later use\n",
    "    workbooks[key] = destination_wb\n",
    "    worksheets[key] = destination_ws\n",
    "\n",
    "# Get all the generator files that start with \"PEMMDB\" and end with \".xlsx\"\n",
    "generators_files = sorted(f for f in os.listdir(folder_source_files_generators) if (f.startswith(\"PEMMDB\") and f.endswith(\".xlsx\")))\n",
    "\n",
    "# Define the starting row in the destination file for writing generator data\n",
    "row_start = 7\n",
    "\n",
    "# Initialize row counters for each generator type\n",
    "cur_row_ror = 0\n",
    "cur_row_storage = 0\n",
    "cur_row_vres = 0\n",
    "cur_row_thermal = 0\n",
    "\n",
    "# Iterate through each generator file\n",
    "for filename in generators_files:\n",
    "    file_path = os.path.join(folder_source_files_generators, filename)  # Full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a valid file\n",
    "\n",
    "        # Load the generator data from the Excel file\n",
    "        generators_wb = pd.ExcelFile(file_path)\n",
    "        print(file_path)\n",
    "\n",
    "        # Load individual sheets from the generator Excel file\n",
    "        hydro_df = generators_wb.parse('Hydro')\n",
    "        thermal_df = generators_wb.parse('Thermal')\n",
    "        otherNonRes_df = generators_wb.parse('Other Non-RES')\n",
    "        battery_df = generators_wb.parse('Battery')\n",
    "        wind_df = generators_wb.parse('Wind')\n",
    "        solar_df = generators_wb.parse('Solar')\n",
    "        otherRes_df = generators_wb.parse('Other RES')\n",
    "\n",
    "        # Process data for Run-of-River (RoR) plants\n",
    "        if round((hydro_df.iloc[7, 1]+hydro_df.iloc[10, 1]),1) > 0:\n",
    "            # Add data for RoR generation to the worksheet\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=2, value = filename.split('_')[1]+'ROR') # PP Name\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=3, value = df_other_sources_RoR.iloc[3, 1]) # Tec\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=5, value = df_other_sources_RoR.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=6, value = round(hydro_df.iloc[7, 1]+hydro_df.iloc[10, 1],1)) # MaxProd\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=7, value = df_other_sources_RoR.iloc[7, 1]) # MinProd\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=8, value = df_other_sources_RoR.iloc[8, 1]) # MaxCons\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=9, value = df_other_sources_RoR.iloc[9, 1]) # DisEffic\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=10, value = df_other_sources_RoR.iloc[10, 1]) # ChEffic\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=11, value = df_other_sources_RoR.iloc[11, 1]) # Qmax\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=12, value = df_other_sources_RoR.iloc[12, 1]) # Qmin\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=14, value = df_other_sources_RoR.iloc[14, 1]) # MinReserve\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=15, value = df_other_sources_RoR.iloc[15, 1]) # IniReserve\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=16, value = df_other_sources_RoR.iloc[16, 1]) # IsHydro\n",
    "            worksheets['RoR'].cell(row=row_start+cur_row_ror, column=22, value = df_other_sources_RoR.iloc[22, 1]) # Ene2PowRatio\n",
    "            \n",
    "            cur_row_ror += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Hydro Storage (HS)\n",
    "        if round(hydro_df.iloc[13, 1],1) > 0:\n",
    "            # Add data for Hydro Storage to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'HS') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_HS.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_HS.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(hydro_df.iloc[13, 1],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_HS.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = df_other_sources_Storage_HS.iloc[8, 1]) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = df_other_sources_Storage_HS.iloc[9, 1]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = df_other_sources_Storage_HS.iloc[10, 1]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_HS.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_HS.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_HS.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_HS.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=16, value = df_other_sources_Storage_HS.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_HS.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((hydro_df.iloc[12, 1]*1000)/hydro_df.iloc[13, 1],1)) # Ene2PowRatio\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "        \n",
    "        # Process data for Hydro Pumped Storage (HPS)\n",
    "        if round(hydro_df.iloc[16, 1],1) > 0:\n",
    "            # Add data for Hydro Pumped Storage to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'HPS') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_HPS.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_HPS.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(hydro_df.iloc[16, 1],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_HPS.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = -round(hydro_df.iloc[17, 1],1)) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = df_other_sources_Storage_HPS.iloc[9, 1]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = df_other_sources_Storage_HPS.iloc[10, 1]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_HPS.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_HPS.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_HPS.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_HPS.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=16, value = df_other_sources_Storage_HPS.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_HPS.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((hydro_df.iloc[15, 1]*1000)/hydro_df.iloc[16, 1],1)) # Ene2PowRatio\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Hydro Pumped Storage Closed Loop (HPSCl)\n",
    "        if round(hydro_df.iloc[20, 1],1) > 0:\n",
    "            # Add data for Hydro Pumped Storage Closed Loop to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'HPSCL') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_HPSCL.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_HPSCL.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(hydro_df.iloc[20, 1],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_HPSCL.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = -round(hydro_df.iloc[21, 1],1)) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = df_other_sources_Storage_HPSCL.iloc[9, 1]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = df_other_sources_Storage_HPSCL.iloc[10, 1]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_HPSCL.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_HPSCL.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_HPSCL.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_HPSCL.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=16, value = df_other_sources_Storage_HPSCL.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_HPSCL.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((hydro_df.iloc[19, 1]*1000)/hydro_df.iloc[20, 1],1)) # Ene2PowRatio\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Batteries (BESS)\n",
    "        if round(battery_df.iloc[10, 2],1) > 0:\n",
    "            # Add data for Batteries to the worksheet\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=2, value = filename.split('_')[1]+'BESS') # PP Name\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=3, value = df_other_sources_Storage_BESS.iloc[3, 1]) # Tec\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=5, value = df_other_sources_Storage_BESS.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=6, value = round(battery_df.iloc[10, 2],1)) # MaxProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=7, value = df_other_sources_Storage_BESS.iloc[7, 1]) # MinProd\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=8, value = round(battery_df.iloc[10, 3],1)) # MaxCons\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=9, value = battery_df.iloc[10, 6]) # DisEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=10, value = battery_df.iloc[10, 6]) # ChEffic\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=11, value = df_other_sources_Storage_BESS.iloc[11, 1]) # Qmax\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=12, value = df_other_sources_Storage_BESS.iloc[12, 1]) # Qmin\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=14, value = df_other_sources_Storage_BESS.iloc[14, 1]) # MinReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=15, value = df_other_sources_Storage_BESS.iloc[15, 1]) # IniReserve\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_BESS.iloc[16, 1]) # IsHydro\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=17, value = df_other_sources_Storage_BESS.iloc[17, 1]) # OMVarCost\n",
    "            worksheets['Storage'].cell(row=row_start+cur_row_storage, column=22, value = round((battery_df.iloc[10, 4])/battery_df.iloc[10, 2],1)) # Ene2PowRatio\n",
    "\n",
    "            cur_row_storage += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Wind power plants\n",
    "        if round(wind_df.iloc[6, 1],1) > 0:\n",
    "            # Add data for Wind power plants to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=2, value = filename.split('_')[1]+'WIND') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = df_other_sources_VRES_Wind.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = df_other_sources_VRES_Wind.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = round(wind_df.iloc[6, 1]*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = df_other_sources_VRES_Wind.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_Wind.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=10, value = df_other_sources_VRES_Wind.iloc[10, 1]) # OMVarCost\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Wind Offshore power plants\n",
    "        if round(wind_df.iloc[7, 1],1) > 0:\n",
    "            # Add data for Wind Offshore power plants to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=2, value = filename.split('_')[1]+'WINDOFF') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = df_other_sources_VRES_WindOff.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = df_other_sources_VRES_WindOff.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = round(wind_df.iloc[7, 1]*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = df_other_sources_VRES_WindOff.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_WindOff.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=10, value = df_other_sources_VRES_WindOff.iloc[10, 1]) # OMVarCost\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Photovoltaic (PV) power plants\n",
    "        if round(solar_df.iloc[7, 1]+solar_df.iloc[8, 1],1) > 0:\n",
    "            # Add data for Photovoltaik power plants to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=2, value = filename.split('_')[1]+'PV') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = df_other_sources_VRES_PV.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = df_other_sources_VRES_PV.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = round((solar_df.iloc[7, 1]+solar_df.iloc[8, 1])*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = df_other_sources_VRES_PV.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_PV.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=10, value = df_other_sources_VRES_PV.iloc[10, 1]) # OMVarCost\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Concentrated Solar Power (CSP)\n",
    "        if round(solar_df.iloc[6, 1]+solar_df.iloc[9, 1],1) > 0:\n",
    "            # Add data for Concentrated Solar Power to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=2, value = filename.split('_')[1]+'CSP') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = df_other_sources_VRES_CSP.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = df_other_sources_VRES_CSP.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = round((solar_df.iloc[6, 1]+solar_df.iloc[9, 1])*1000,1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = df_other_sources_VRES_CSP.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_CSP.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=10, value = df_other_sources_VRES_CSP.iloc[10, 1]) # OMVarCost\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Process data for Other Renewable Energy Sources (OtherRES)\n",
    "        if round(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8],1) > 0:\n",
    "            # Add data for Other Renewable Energy Sources to the worksheet\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=2, value = filename.split('_')[1]+'OTHERRES') # PP Name\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=3, value = df_other_sources_VRES_OtherRES.iloc[3, 1]) # Tec\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=4, value = filename.split('_')[1]) # Node/Businfo\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=5, value = df_other_sources_VRES_OtherRES.iloc[5, 1]) # ExisUnit\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=6, value = round(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8],1)) # MaxProd\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=7, value = df_other_sources_VRES_OtherRES.iloc[7, 1]) # EnableInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=8, value = df_other_sources_VRES_OtherRES.iloc[8, 1]) # MaxInvest\n",
    "            worksheets['VRES'].cell(row=row_start+cur_row_vres, column=10, value = df_other_sources_VRES_OtherRES.iloc[10, 1]) # OMVarCost\n",
    "\n",
    "            cur_row_vres += 1 # Move to the next row\n",
    "\n",
    "        # Mapping of thermal power sources to their respective DataFrames\n",
    "        thermal_sources = {\n",
    "            \"NUCLEAR\": df_other_sources_Thermal_Nuclear,\n",
    "            \"COALOLD1\": df_other_sources_Thermal_CoalOld1,\n",
    "            \"COALOLD2\": df_other_sources_Thermal_CoalOld2,\n",
    "            \"COALNEW\": df_other_sources_Thermal_CoalNew,\n",
    "            \"COALCCS\": df_other_sources_Thermal_CoalCCS,\n",
    "            \"LIGNITEOLD1\": df_other_sources_Thermal_LigniteOld1,\n",
    "            \"LIGNITEOLD2\": df_other_sources_Thermal_LigniteOld2,\n",
    "            \"LIGNITENEW\": df_other_sources_Thermal_LigniteNew,\n",
    "            \"LIGNITECCS\": df_other_sources_Thermal_LigniteCCS,\n",
    "            \"GASCONVOLD1\": df_other_sources_Thermal_GasConvOld1,\n",
    "            \"GASCONVOLD2\": df_other_sources_Thermal_GasConvOld2,\n",
    "            \"GASCCGTOLD1\": df_other_sources_Thermal_GasCCGTOld1,\n",
    "            \"GASCCGTOLD2\": df_other_sources_Thermal_GasCCGTOld2,\n",
    "            \"GASCCGTNEW\": df_other_sources_Thermal_GasCCGTNew,\n",
    "            \"GASCCGTCCS\": df_other_sources_Thermal_GasCCGTCCS,\n",
    "            \"GASOCGTOLD\": df_other_sources_Thermal_GasOCGTOld,\n",
    "            \"GASOCGTNEW\": df_other_sources_Thermal_GasOCGTNew,\n",
    "            \"LIGHTOIL\": df_other_sources_Thermal_LightOil,\n",
    "            \"HEAVYOILOLD1\": df_other_sources_Thermal_HeavyOilOld1,\n",
    "            \"HEAVYOILOLD2\": df_other_sources_Thermal_HeavyOilOld2,\n",
    "            \"OILSHALEOLD\": df_other_sources_Thermal_OilShaleOld,\n",
    "            \"OILSHALENEW\": df_other_sources_Thermal_OilShaleNew,\n",
    "            \"GASCCGTPRESENT1\": df_other_sources_Thermal_GasCCGTPresent1,\n",
    "            \"GASCCGTPRESENT2\": df_other_sources_Thermal_GasCCGTPresent2,\n",
    "        }\n",
    "\n",
    "        # Define fuel price index for each thermal power source\n",
    "        price_indices = {\n",
    "            \"NUCLEAR\": 2, \"COALOLD1\": 7, \"COALOLD2\": 7, \"COALNEW\": 7, \"COALCCS\": 7, \"LIGNITEOLD1\": 3, \"LIGNITEOLD2\": 3, \"LIGNITENEW\": 3, \"LIGNITECCS\": 3,\n",
    "            \"GASCONVOLD1\": 8, \"GASCONVOLD2\": 8, \"GASCCGTOLD1\": 8, \"GASCCGTOLD2\": 8, \"GASCCGTPRESENT1\": 8,\n",
    "            \"GASCCGTPRESENT2\": 8, \"GASCCGTNEW\": 8, \"GASCCGTCCS\": 8, \"GASOCGTOLD\": 8, \"GASOCGTNEW\": 8,\n",
    "            \"LIGHTOIL\": 14, \"HEAVYOILOLD1\": 15, \"HEAVYOILOLD2\": 15, \"OILSHALEOLD\": 20, \"OILSHALENEW\": 20,\n",
    "        }\n",
    "\n",
    "        # Iterate over each thermal power source and write data to the worksheet\n",
    "        for idx, (source_name, df_source) in enumerate(thermal_sources.items(), start=10):\n",
    "            actual_idx = 10 + (idx - 10) * 2  # Ensure idx increments by 2 instead of 1\n",
    "\n",
    "            # Process only if MaxProd is greater than 0\n",
    "            if round(thermal_df.iloc[actual_idx, 2], 1) > 0:\n",
    "                price_index = price_indices.get(source_name)  # Get fuel price index\n",
    "\n",
    "                # Extract country code from filename\n",
    "                filename_part = filename.split('_')[1]\n",
    "                if filename_part[2:4] == '00':\n",
    "                    countryCode = filename_part[:2]  # First two characters\n",
    "                else:\n",
    "                    countryCode = filename_part  # Full identifier\n",
    "\n",
    "                # Write data to the 'Thermal' worksheet\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=2, value=filename.split('_')[1] + source_name)  # PP Name\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=3, value=df_source.iloc[3, 1])  # Tec\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=4, value=filename.split('_')[1])  # Node/Businfo\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=5, value=df_source.iloc[5, 1])  # ExisUnit\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=6, value=round(thermal_df.iloc[actual_idx, 2], 1))  # MaxProd\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=7, value=df_source.iloc[7, 1])  # MinProd\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=8, value=round(thermal_df.iloc[actual_idx, 2], 1))  # RampUp\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=9, value=round(thermal_df.iloc[actual_idx, 2], 1))  # RampDw\n",
    "                \n",
    "                # Determine fuel cost based on country and source type\n",
    "                if (\"lignite\" in source_name.lower() and countryCode in ['BG', 'MK', 'CZ']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=round(df_prices.iloc[3, 2] * 3.6 / 860, 4))\n",
    "                elif (\"lignite\" in source_name.lower() and countryCode in ['SK', 'DE', 'RS', 'PL', 'ME', 'UKNI', 'BA', 'IE']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=round(df_prices.iloc[4, 2] * 3.6 / 860, 4))\n",
    "                elif (\"lignite\" in source_name.lower() and countryCode in ['SI', 'RO', 'HU']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=round(df_prices.iloc[5, 2] * 3.6 / 860, 4))\n",
    "                elif (\"lignite\" in source_name.lower() and countryCode in ['GR', 'TR']):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=round(df_prices.iloc[6, 2] * 3.6 / 860, 4))\n",
    "                elif (\"lignite\" in source_name.lower()):\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=99999)\n",
    "                else:\n",
    "                    worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=round(df_prices.iloc[price_index, 2] * 3.6 / 860, 4))  # FuelCost\n",
    "                \n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=14, value=round(860 / df_source.iloc[14, 1], 4))  # SlopeVarCost\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=15, value=df_source.iloc[15, 1])  # InterVarCost\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=df_source.iloc[16, 1])  # OMVarCost\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17, value=df_source.iloc[17, 1])  # StartUpCost\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=19, value=df_source.iloc[19, 1])  # EnableInvest\n",
    "                worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=22, value=round(df_source.iloc[22, 1] * 3.6, 3))  # CO2Emis\n",
    "                \n",
    "                cur_row_thermal += 1  # Move to the next row\n",
    "\n",
    "        # Save workbook after processing all thermal power sources\n",
    "        workbooks[\"Thermal\"].save(files[\"Thermal\"][1])\n",
    "\n",
    "        if round(otherNonRes_df.iloc[7, 2],1) > 0:\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=2, value=filename.split('_')[1] + 'OTHERNONRES')  # PP Name\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=3, value=df_other_sources_Thermal_OtherNonRES.iloc[3, 1])  # Tec\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=4, value=filename.split('_')[1])  # Node/Businfo\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=5, value=df_other_sources_Thermal_OtherNonRES.iloc[5, 1])  # ExisUnit\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=6, value=round(otherNonRes_df.iloc[7, 2], 1))  # MaxProd\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=7, value=df_other_sources_Thermal_OtherNonRES.iloc[7, 1])  # MinProd\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=8, value=round(otherNonRes_df.iloc[7, 2], 1))  # RampUp\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=9, value=round(otherNonRes_df.iloc[7, 2], 1))  # RampDw\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=13, value=round(df_prices.iloc[12, 2] * 3.6 / 860, 4))  # FuelCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=14, value=round(860 / df_other_sources_Thermal_OtherNonRES.iloc[14, 1], 4))  # SlopeVarCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=15, value=df_other_sources_Thermal_OtherNonRES.iloc[15, 1])  # InterVarCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=16, value=df_other_sources_Thermal_OtherNonRES.iloc[16, 1])  # OMVarCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=17, value=df_other_sources_Thermal_OtherNonRES.iloc[17, 1])  # StartUpCost\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=19, value=df_other_sources_Thermal_OtherNonRES.iloc[19, 1])  # EnableInvest\n",
    "            worksheets['Thermal'].cell(row=row_start + cur_row_thermal, column=22, value=round(df_other_sources_Thermal_OtherNonRES.iloc[22, 1] * 3.6, 3))  # CO2Emis\n",
    "\n",
    "            cur_row_thermal += 1 # Move to the next row\n",
    "\n",
    "# Save and close notebooks\n",
    "workbooks[\"RoR\"].save(files[\"RoR\"][1])\n",
    "workbooks[\"RoR\"].close()\n",
    "workbooks[\"Storage\"].save(files[\"Storage\"][1])\n",
    "workbooks[\"Storage\"].close()\n",
    "workbooks[\"VRES\"].save(files[\"VRES\"][1])\n",
    "workbooks[\"VRES\"].close()\n",
    "workbooks[\"Thermal\"].save(files[\"Thermal\"][1])\n",
    "workbooks[\"Thermal\"].close()\n",
    "\n",
    "print(f\"Generator data saved successfully copied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Power_VRESProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_AT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_BE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_CY00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_DZ00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_EG00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_ES00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_FR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_FR15_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_GR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_GR03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_IL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_ITS1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_ITSI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_LV00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_MA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_MD00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_PS00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_PT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_TR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_UA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_CSP_noStorage_2030_UK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITCA_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITCN_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITCS_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITN1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITS1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITSA_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPVRooftop_2030_ITSI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_AL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_AT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_BA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_BE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_BG00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_CH00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_CY00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_CZ00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_DE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_DKE1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_DKW1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_DZ00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_EE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_EG00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_ES00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_FI00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_FR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_FR15_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_GE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_GR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_GR03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_HR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_HU00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_IE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_IL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_LT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_LU00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_LUG1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_LV00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_LY00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_MA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_MD00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_ME00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_MK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_MT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_NL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_NOM1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_NOS0_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_PL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_PS00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_PT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_RO00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_RS00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_SE02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_SE03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_SE04_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_SI00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_SK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_TN00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_TR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_UA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_UK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_UKNI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_LFSolarPV_2030_XK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_BE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_BEIOH01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_BEOF_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_BEOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DE011_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DE012_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DE013_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DE02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DEOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DEOH002_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DEOR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKBH_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKE1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKEOR01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKKF_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKW11_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKW12_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKW1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKWOH01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_DKWOR01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_EE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_EEOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ES00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ESOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ESOH002_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ESOH003_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FI00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FI02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FIOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR04_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR08_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR09_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FR13_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FROH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FROH002_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_FROH003_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_GR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_GR03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_GROR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_HR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_HR01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_IE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_IEOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITCAOR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITCA_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITCNOR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITCN_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITCSOR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITCS_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITN1OR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITN1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITS1OR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITS1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITSAOR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITSA_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITSIOR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ITSI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_LT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_LTOR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_LV00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_LVOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NL011_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NL012_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NL031_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NL032_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NL033_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NLLL_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NLOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NLOR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NOM1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NOMOH01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NON1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NONOH01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NOS0_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NOSOH01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NOSOH02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_NOSOR01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_PL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_PLOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_PT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_PTOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_RO00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_ROOR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SE01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SE02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SE03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SE04_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SEOH001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SEOH002_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SEOH003_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_SEOR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKNIOR1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKNI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKOH003_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKOH004_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKOH005_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKOH006_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Offshore_2030_UKOR001_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_AL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_AT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_BA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_BE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_BG00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_CH00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_CY00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_CZ00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_DE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_DKE1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_DKW1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_DZ00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_EE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_EG00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ES00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_FI00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_FR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_FR15_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_GE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_GR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_GR03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_HR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_HU00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_IE00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_IL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITCA_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITCN_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITCS_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITN1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITS1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITSA_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ITSI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_LT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_LU00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_LUG1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_LV00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_LY00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_MA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_MD00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_ME00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_MK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_NL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_NOM1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_NON1_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_NOS0_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_PL00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_PS00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_PT00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_RO00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_RS00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_SE01_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_SE02_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_SE03_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_SE04_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_SI00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_SK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_TN00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_TR00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_UA00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_UK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_UKNI_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PECD/2030\\PECD_Wind_Onshore_2030_XK00_edition 2023.2.csv\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_AL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_AT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_BA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_BE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_BEOF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_BG00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_CH00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_CY00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_CZ00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DEKF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DKBH_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DKE1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DKKF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DKNS_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DKW1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_DZ00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_EE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_EEOF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_EG00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ES00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_FI00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_FR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_FR15_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_GE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_GR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_GR03_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_HR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_HU00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_IE00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_IL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITCA_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITCN_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITCS_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITN1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITS1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITSA_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ITSI_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LTOF_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LUB1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LUF1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LUG1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LUV1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LV00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_LY00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_MA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_MD00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_ME00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_MK00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_MT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NL60_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NL6H_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NLA0_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NLBH_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NLLL_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NOM1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NON1_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_NOS0_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_PL00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_PS00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_PT00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_RO00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_RS00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_SE01_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_SE02_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_SE03_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_SE04_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_SI00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_SK00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_TN00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_TR00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_UA00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_UK00_NationalTrends_2030.xlsx\n",
      "L:\\TYNDP 24\\Data\\PEMMDB2/2030\\PEMMDB_UKNI_NationalTrends_2030.xlsx\n",
      "Data saved successfully at: L:\\TYNDP 24\\Results\\V2G_2030_NT\\Power_VRESProfiles.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source and destination files\n",
    "if simulation_year == 2030:\n",
    "    folder_source_files_VRESProfiles = os.path.join(tyndp_dir, 'PECD/2030')\n",
    "    folder_source_files_OtherRESProfiles = os.path.join(tyndp_dir, 'PEMMDB2/2030')\n",
    "elif simulation_year == 2040:\n",
    "    folder_source_files_VRESProfiles = os.path.join(tyndp_dir, 'PECD/2040')\n",
    "    folder_source_files_OtherRESProfiles = os.path.join(tyndp_dir, 'PEMMDB2/2040')\n",
    "elif simulation_year == 2050:\n",
    "    folder_source_files_VRESProfiles = os.path.join(tyndp_dir, 'PECD/2050')\n",
    "    folder_source_files_OtherRESProfiles = os.path.join(tyndp_dir, 'PEMMDB2/2050')\n",
    "else:\n",
    "    sys.exit(f\"Invalid simulation year: {simulation_year}. Please use 2030, 2040, or 2050.\")\n",
    "\n",
    "template_file_VRESProfiles = os.path.join(template_dir, 'Power_VRESProfiles.xlsx')\n",
    "destination_file_VRESProfiles = os.path.join(destination_dir, 'Power_VRESProfiles.xlsx')\n",
    "\n",
    "# Prepare the destination file by removing it if it already exists\n",
    "if os.path.exists(destination_file_VRESProfiles):\n",
    "    if is_file_open(destination_file_VRESProfiles):\n",
    "        sys.exit(f\"File '{destination_file_VRESProfiles}' is currently open by another application.\")\n",
    "    os.remove(destination_file_VRESProfiles)\n",
    "\n",
    "# Copy the template file to the destination directory\n",
    "shutil.copy(template_file_VRESProfiles, destination_file_VRESProfiles)\n",
    "\n",
    "# If there is no file for Wind_Offshore_2030_BEOF, copy the Wind_Offshore_2030_BE00 file and rename it\n",
    "if not os.path.exists(os.path.join(tyndp_dir, 'PECD/2030/PECD_Wind_Offshore_2030_BEOF_edition 2023.2.csv')):\n",
    "    shutil.copy(os.path.join(tyndp_dir, 'PECD/2030/PECD_Wind_Offshore_2030_BE00_edition 2023.2.csv'), os.path.join(tyndp_dir, 'PECD/2030/PECD_Wind_Offshore_2030_BEOF_edition 2023.2.csv'))\n",
    "\n",
    "# Load the destination workbook and worksheet\n",
    "destination_wb = load_workbook(destination_file_VRESProfiles)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Get the list of VRES profile files to process\n",
    "vres_profiles_files = sorted(f for f in os.listdir(folder_source_files_VRESProfiles) if (f.startswith(\"PECD\") and f.endswith(\".csv\")))\n",
    "\n",
    "# Starting row in destination file\n",
    "row_start = 7\n",
    "\n",
    "# Process each VRES profile file\n",
    "for filename in vres_profiles_files:\n",
    "    file_path = os.path.join(folder_source_files_VRESProfiles, filename)  # Full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a valid file\n",
    "\n",
    "        # Identify the type of technology from the filename\n",
    "        matched_tec = [tec for tec in ['_CSP_noStorage_', '_LFSolarPV_', '_LFSolarPVRooftop_', '_Wind_Offshore_', '_Wind_Onshore_'] if tec in filename]\n",
    "        if matched_tec:\n",
    "            print(file_path) # Log the file being processed\n",
    "        else:\n",
    "            continue # Skip files that don't match the expected technologies\n",
    "            \n",
    "        # Load the VRES profile data (skip header rows, select the first 8760 rows for hourly data)\n",
    "        vres_profiles = pd.read_csv(file_path, skiprows=10, header=0, nrows=8760)\n",
    "\n",
    "        # Check if the selected year is present in the columns (year columns start from index 2)\n",
    "        year_columns = vres_profiles.columns[2:]\n",
    "        for y in year_columns:\n",
    "            if '.' in y:\n",
    "                year_columns = year_columns.str.replace('.0', '') # Remove .0 suffix if present\n",
    "        if (str(cy_year) not in year_columns):\n",
    "            print(f\"Year {cy_year} not found in sheet {filename}. Skipping node.\")\n",
    "            continue # Skip if the year is not found\n",
    "\n",
    "        # Get the column index for the selected year\n",
    "        year_col_idx = year_columns.get_loc(str(cy_year)) + 2  # Adjust for 1-based index in Excel\n",
    "\n",
    "\n",
    "        # Extract the time series for the selected year (8760 hours)\n",
    "        time_series = vres_profiles.iloc[:, year_col_idx].fillna(0) # Fill missing values with 0\n",
    "\n",
    "        # Skip if the entire time series is zero\n",
    "        if time_series.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Write data to the destination worksheet (PP name, technology, node information)\n",
    "        destination_ws[f'B{row_start}'] = 'rp01' # Periode\n",
    "        destination_ws[f'C{row_start}'] = filename.split('_')[-2] # Write node name (second last part of the filename)\n",
    "        \n",
    "        # Determine the technology based on the filename and write it to column D\n",
    "        if filename.split('_')[1]+filename.split('_')[2] == 'CSPnoStorage':\n",
    "            destination_ws[f'D{row_start}'] = 'CSP'\n",
    "        elif ((filename.split('_')[1] == 'LFSolarPV') or (filename.split('_')[1] == 'LFSolarPVRooftop')):\n",
    "            destination_ws[f'D{row_start}'] = 'Solar'\n",
    "        elif filename.split('_')[1]+filename.split('_')[2] == 'WindOffshore':\n",
    "            destination_ws[f'D{row_start}'] = 'Offshore'\n",
    "        elif filename.split('_')[1]+filename.split('_')[2] == 'WindOnshore':\n",
    "            destination_ws[f'D{row_start}'] = 'Wind'\n",
    "        else:\n",
    "            continue # Skip if the technology is not recognized\n",
    "\n",
    "        # Write the time series data (8760 hours) starting from column E\n",
    "        column_start = 5\n",
    "        for cf in time_series: # Iterate over the time series values\n",
    "            destination_ws.cell(row=row_start, column=column_start, value=round(cf,4))\n",
    "            column_start += 1 # Move to the next column\n",
    "    \n",
    "        row_start += 1  # Move to the next row for the next entry\n",
    "\n",
    "# Process Other RES profile files\n",
    "otherRES_profiles_files = sorted(f for f in os.listdir(folder_source_files_OtherRESProfiles) if (f.startswith(\"PEMMDB\") and f.endswith(\".xlsx\")))\n",
    "\n",
    "for filename in otherRES_profiles_files:\n",
    "    file_path = os.path.join(folder_source_files_OtherRESProfiles, filename)  # Full file path\n",
    "    if os.path.isfile(file_path):  # Ensure it's a valid file\n",
    "\n",
    "        # Load the Excel file and process the data\n",
    "        generators_wb = pd.ExcelFile(file_path)\n",
    "        print(file_path) # Log the file being processed\n",
    "\n",
    "        otherRes_df = generators_wb.parse('Other RES')\n",
    "\n",
    "        # Check if the total generation for the selected year is greater than zero\n",
    "        if round(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8],1) > 0:\n",
    "            destination_ws[f'B{row_start}'] = 'rp01' # Periode\n",
    "            destination_ws[f'C{row_start}'] = filename.split('_')[1] # Node name\n",
    "            destination_ws[f'D{row_start}'] = 'OtherRES' # Technology\n",
    "\n",
    "            # Write the time series data (8760 hours) starting from column E\n",
    "            column_start = 5\n",
    "            for i in range(8760): # Iterate over the time series values\n",
    "                destination_ws.cell(row=row_start, column=column_start, value=round((otherRes_df.iloc[9, 4]+otherRes_df.iloc[9, 5]+otherRes_df.iloc[9, 6]+otherRes_df.iloc[9, 7]+otherRes_df.iloc[9, 8])/(otherRes_df.iloc[7, 4]+otherRes_df.iloc[7, 5]+otherRes_df.iloc[7, 6]+otherRes_df.iloc[7, 7]+otherRes_df.iloc[7, 8]),4))\n",
    "                column_start += 1 # Move to the next column\n",
    "        \n",
    "            row_start += 1  # Move to the next row for the next entry\n",
    "\n",
    "# Save and close the modified workbook to the destination\n",
    "destination_wb.save(destination_file_VRESProfiles)\n",
    "destination_wb.close()\n",
    "\n",
    "print(f\"Data saved successfully at: {destination_file_VRESProfiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Post-Tasks\n",
    "This includes extracting or generating electrical parameters for power lines from PyPSA data and removing unnecessary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Electric Parameters for Network\n",
    "The electrical parameters (X values) for power lines are sourced from PyPSA data stored in PyPSA_Data/Power_Network_PyPSA.xlsx.\n",
    "If a connection is not available in the PyPSA data, a rough estimate is derived based on the relationship between X and Pmax within the existing PyPSA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line parameters updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for source and destination files\n",
    "source_file_line_parameters = os.path.join(pypsa_dir, 'Power_Network_PyPSA.xlsx')\n",
    "destination_file_Network = os.path.join(destination_dir, 'Power_Network.xlsx')\n",
    "\n",
    "if is_file_open(destination_file_Network):\n",
    "    sys.exit(f\"File '{destination_file_Network}' is currently open by another application.\")\n",
    "\n",
    "# Load data from the source and destination Excel files\n",
    "df_pypsa_lines = pd.read_excel(source_file_line_parameters, skiprows=5) # Data from PyPSA source file\n",
    "df_power_network = pd.read_excel(destination_file_Network, skiprows=5) # Data from the destination network file\n",
    "\n",
    "# Create a combined identifier by concatenating columns 1 and 2, removing spaces\n",
    "df_pypsa_lines[\"combined\"] = (df_pypsa_lines.iloc[:, 1] + df_pypsa_lines.iloc[:, 2]).str.replace(\" \", \"\", regex=True)\n",
    "df_pypsa_lines = df_pypsa_lines.drop_duplicates(subset=\"combined\") # Remove duplicate combined entries\n",
    "\n",
    "# Create a combined identifier for the power network file, similar to the PyPSA file\n",
    "df_power_network[\"combined\"] = df_power_network[\"combined\"] = (df_power_network.iloc[:, 1] + df_power_network.iloc[:, 2]).str.replace(\" \", \"\", regex=True)\n",
    "\n",
    "# Map the line parameters from the PyPSA file to the destination network file based on the \"combined\" column\n",
    "df_power_network.iloc[:, 6] = df_power_network[\"combined\"].map(\n",
    "    df_pypsa_lines.set_index(\"combined\").iloc[:, 6]\n",
    ")\n",
    "\n",
    "# Fill missing values in the line parameters using a mathematical formula\n",
    "df_power_network.iloc[:, 6] = df_power_network.iloc[:, 6].fillna(\n",
    "    14527 * df_power_network.iloc[:, 10] ** (-0.77)\n",
    ")\n",
    "\n",
    "# Calculate the line parameters in pu\n",
    "df_power_network.iloc[:, 6] = round(df_power_network.iloc[:, 6]/(((380*10^3)**2)/(100*10^6)),15)\n",
    "\n",
    "# Load the destination workbook and worksheet for saving the changes\n",
    "destination_wb = load_workbook(destination_file_Network)\n",
    "destination_ws = destination_wb.active\n",
    "\n",
    "# Write the adjusted line parameters into the destination worksheet, starting from row 7\n",
    "start_row = 7\n",
    "for i, value in enumerate(df_power_network.iloc[:, 0], start=start_row):\n",
    "    destination_ws[f'G{i}'] = df_power_network.iloc[i-start_row, 6]\n",
    "\n",
    "# Save the modified workbook to the destination\n",
    "destination_wb.save(destination_file_Network)\n",
    "destination_wb.close()\n",
    "\n",
    "print(\"Line parameters updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Cleanup\n",
    "Removes unnecessary data that was copied during processing:\n",
    "\n",
    "- Deletes demand and generators from nodes that are not listed in *Power_BusInfo.xlsx*.\n",
    "- Removes inflows for RoR or storage units that are not listed in *Power_RoR.xlsx* or *Power_Storage*.\n",
    "- Deletes NTCs and power lines that reference buses not found in *P*ower_BusInfo.xlsx*.\n",
    "- Removes VRES profiles for VRES generators units that are not listed in *Power_VRES*.\n",
    "\n",
    "**IMPORTANT**:\n",
    "If you want to include only a subset of countries in the final dataset, first remove all unwanted countries from *Power_BusInfo.xlsx* in the specified `destination_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Power_Demand\n",
    "Deletes demand from nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7 with node None will be deleted.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power Demand data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power Bus Information and Power Demand data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_demand = os.path.join(destination_dir, 'Power_Demand.xlsx')\n",
    "\n",
    "if is_file_open(file_demand):\n",
    "    sys.exit(f\"File '{file_demand}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx and extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_Demand.xlsx to filter nodes based on validity\n",
    "demand_wb = load_workbook(file_demand) # Load the Power Demand workbook\n",
    "demand_ws = demand_wb.active\n",
    "\n",
    "# Collect rows to delete based on invalid node values\n",
    "delete_rows = [] # List to store rows that should be deleted\n",
    "for row_idx, row in enumerate(demand_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check for invalid or missing nodes\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} will be deleted.\")\n",
    "\n",
    "# Delete rows in reverse order to avoid index shifting during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    demand_ws.delete_rows(row_idx) # Delete invalid rows from the workbook\n",
    "\n",
    "# Save and close the updated Power_Demand.xlsx\n",
    "demand_wb.save(file_demand)\n",
    "demand_wb.close()\n",
    "\n",
    "print(\"Power Demand data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Power_RoR\n",
    "Deletes RoR generators with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15 with node EG00 is marked for deletion.\n",
      "Row 18 with node FR15 is marked for deletion.\n",
      "Row 19 with node GE00 is marked for deletion.\n",
      "Row 34 with node MA00 is marked for deletion.\n",
      "Row 47 with node TR00 is marked for deletion.\n",
      "Row 48 with node UA00 is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power RoR data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power Bus Information and Power RoR data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_RoR = os.path.join(destination_dir, 'Power_RoR.xlsx')\n",
    "\n",
    "if is_file_open(file_RoR):\n",
    "    sys.exit(f\"File '{file_RoR}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_RoR.xlsx to filter nodes based on validity\n",
    "ror_wb = load_workbook(file_RoR) # Load the Power RoR workbook\n",
    "ror_ws = ror_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(ror_ws.iter_rows(min_row=7, min_col=4, max_col=4, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    ror_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_RoR.xlsx with updated data\n",
    "ror_wb.save(file_RoR)\n",
    "ror_wb.close()\n",
    "\n",
    "print(\"Power RoR data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Power_Storage\n",
    "Deletes storage units with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 43 with node FR15 is marked for deletion.\n",
      "Row 44 with node GE00 is marked for deletion.\n",
      "Row 56 with node IL00 is marked for deletion.\n",
      "Row 83 with node MA00 is marked for deletion.\n",
      "Row 118 with node TR00 is marked for deletion.\n",
      "Row 119 with node TR00 is marked for deletion.\n",
      "Row 120 with node UA00 is marked for deletion.\n",
      "Row 121 with node UA00 is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power Storage data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power Bus Information and Power Storage data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_storage = os.path.join(destination_dir, 'Power_Storage.xlsx')\n",
    "\n",
    "if is_file_open(file_storage):\n",
    "    sys.exit(f\"File '{file_storage}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_RoR.xlsx to filter nodes based on validity\n",
    "storage_wb = load_workbook(file_storage)\n",
    "storage_ws = storage_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(storage_ws.iter_rows(min_row=7, min_col=4, max_col=4, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    storage_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_Storage.xlsx with updated data\n",
    "storage_wb.save(file_storage)\n",
    "storage_wb.close()\n",
    "\n",
    "print(\"Power Storage data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Power_VRES\n",
    "Deletes VRES generators with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 36 with node DEKF is marked for deletion.\n",
      "Row 41 with node DKKF is marked for deletion.\n",
      "Row 46 with node DZ00 is marked for deletion.\n",
      "Row 50 with node EG00 is marked for deletion.\n",
      "Row 51 with node EG00 is marked for deletion.\n",
      "Row 52 with node EG00 is marked for deletion.\n",
      "Row 66 with node FR15 is marked for deletion.\n",
      "Row 67 with node FR15 is marked for deletion.\n",
      "Row 68 with node GE00 is marked for deletion.\n",
      "Row 69 with node GE00 is marked for deletion.\n",
      "Row 88 with node IL00 is marked for deletion.\n",
      "Row 89 with node IL00 is marked for deletion.\n",
      "Row 131 with node LY00 is marked for deletion.\n",
      "Row 132 with node LY00 is marked for deletion.\n",
      "Row 133 with node MA00 is marked for deletion.\n",
      "Row 134 with node MA00 is marked for deletion.\n",
      "Row 135 with node MA00 is marked for deletion.\n",
      "Row 136 with node MD00 is marked for deletion.\n",
      "Row 137 with node MD00 is marked for deletion.\n",
      "Row 159 with node PS00 is marked for deletion.\n",
      "Row 160 with node PS00 is marked for deletion.\n",
      "Row 191 with node TN00 is marked for deletion.\n",
      "Row 192 with node TN00 is marked for deletion.\n",
      "Row 193 with node TR00 is marked for deletion.\n",
      "Row 194 with node TR00 is marked for deletion.\n",
      "Row 195 with node TR00 is marked for deletion.\n",
      "Row 196 with node UA00 is marked for deletion.\n",
      "Row 197 with node UA00 is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power VRES data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power Bus Information and Power VRES data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_VRES = os.path.join(destination_dir, 'Power_VRES.xlsx')\n",
    "\n",
    "if is_file_open(file_VRES):\n",
    "    sys.exit(f\"File '{file_VRES}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_VRES.xlsx to filter nodes based on validity\n",
    "vres_wb = load_workbook(file_VRES) # Load the Power VRES workbook\n",
    "vres_ws = vres_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(vres_ws.iter_rows(min_row=7, min_col=4, max_col=4, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    vres_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_VRES.xlsx with updated data\n",
    "vres_wb.save(file_VRES)\n",
    "vres_wb.close()\n",
    "\n",
    "print(\"Power VRES data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.5 Power_ThermalGen\n",
    "Deletes thermal generators with nodes that are not listed in *Power_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 84 with node DZ00 is marked for deletion.\n",
      "Row 85 with node DZ00 is marked for deletion.\n",
      "Row 86 with node DZ00 is marked for deletion.\n",
      "Row 87 with node DZ00 is marked for deletion.\n",
      "Row 92 with node EG00 is marked for deletion.\n",
      "Row 93 with node EG00 is marked for deletion.\n",
      "Row 94 with node EG00 is marked for deletion.\n",
      "Row 95 with node EG00 is marked for deletion.\n",
      "Row 96 with node EG00 is marked for deletion.\n",
      "Row 97 with node EG00 is marked for deletion.\n",
      "Row 119 with node FR15 is marked for deletion.\n",
      "Row 120 with node GE00 is marked for deletion.\n",
      "Row 121 with node GE00 is marked for deletion.\n",
      "Row 122 with node GE00 is marked for deletion.\n",
      "Row 157 with node IL00 is marked for deletion.\n",
      "Row 158 with node IL00 is marked for deletion.\n",
      "Row 159 with node IL00 is marked for deletion.\n",
      "Row 160 with node IL00 is marked for deletion.\n",
      "Row 161 with node IL00 is marked for deletion.\n",
      "Row 162 with node IL00 is marked for deletion.\n",
      "Row 207 with node LY00 is marked for deletion.\n",
      "Row 208 with node LY00 is marked for deletion.\n",
      "Row 209 with node LY00 is marked for deletion.\n",
      "Row 210 with node LY00 is marked for deletion.\n",
      "Row 211 with node LY00 is marked for deletion.\n",
      "Row 212 with node LY00 is marked for deletion.\n",
      "Row 213 with node MA00 is marked for deletion.\n",
      "Row 214 with node MA00 is marked for deletion.\n",
      "Row 215 with node MA00 is marked for deletion.\n",
      "Row 216 with node MA00 is marked for deletion.\n",
      "Row 217 with node MA00 is marked for deletion.\n",
      "Row 218 with node MA00 is marked for deletion.\n",
      "Row 219 with node MA00 is marked for deletion.\n",
      "Row 220 with node MA00 is marked for deletion.\n",
      "Row 221 with node MD00 is marked for deletion.\n",
      "Row 222 with node MD00 is marked for deletion.\n",
      "Row 223 with node MD00 is marked for deletion.\n",
      "Row 247 with node PS00 is marked for deletion.\n",
      "Row 248 with node PS00 is marked for deletion.\n",
      "Row 282 with node TN00 is marked for deletion.\n",
      "Row 283 with node TN00 is marked for deletion.\n",
      "Row 284 with node TN00 is marked for deletion.\n",
      "Row 285 with node TN00 is marked for deletion.\n",
      "Row 286 with node TN00 is marked for deletion.\n",
      "Row 287 with node TN00 is marked for deletion.\n",
      "Row 288 with node TR00 is marked for deletion.\n",
      "Row 289 with node TR00 is marked for deletion.\n",
      "Row 290 with node TR00 is marked for deletion.\n",
      "Row 291 with node TR00 is marked for deletion.\n",
      "Row 292 with node TR00 is marked for deletion.\n",
      "Row 293 with node TR00 is marked for deletion.\n",
      "Row 294 with node TR00 is marked for deletion.\n",
      "Row 295 with node TR00 is marked for deletion.\n",
      "Row 296 with node TR00 is marked for deletion.\n",
      "Row 297 with node TR00 is marked for deletion.\n",
      "Row 298 with node TR00 is marked for deletion.\n",
      "Row 299 with node TR00 is marked for deletion.\n",
      "Row 300 with node TR00 is marked for deletion.\n",
      "Row 301 with node UA00 is marked for deletion.\n",
      "Row 302 with node UA00 is marked for deletion.\n",
      "Row 303 with node UA00 is marked for deletion.\n",
      "Row 304 with node UA00 is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power ThermalGen data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power Bus Information and Power ThermalGen data\n",
    "ile_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_thermals = os.path.join(destination_dir, 'Power_ThermalGen.xlsx')\n",
    "\n",
    "if is_file_open(file_thermals):\n",
    "    sys.exit(f\"File '{file_thermals}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid nodes into a set\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook with data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "\n",
    "# Load Power_ThermalGen.xlsx to filter nodes based on validity\n",
    "thermals_wb = load_workbook(file_thermals) # Load the Power ThermalGen workbook\n",
    "thermals_ws = thermals_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(thermals_ws.iter_rows(min_row=7, min_col=4, max_col=4, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    thermals_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_ThermalGen.xlsx with updated data\n",
    "thermals_wb.save(file_thermals)\n",
    "thermals_wb.close()\n",
    "\n",
    "print(\"Power ThermalGen data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Power_Inflows\n",
    "Removes inflows for RoR and storage units that are not listed in *Power_RoR.xlsx* or *Power_Storage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for Power RoR, Power Storage, and Power Inflows\n",
    "file_ror = os.path.join(destination_dir, 'Power_RoR.xlsx')\n",
    "file_storage = os.path.join(destination_dir, 'Power_Storage.xlsx')\n",
    "file_inflows = os.path.join(destination_dir, 'Power_Inflows.xlsx')\n",
    "\n",
    "if is_file_open(file_inflows):\n",
    "    sys.exit(f\"File '{file_inflows}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_RoR.xlsx to extract valid inflow nodes\n",
    "ror_wb = load_workbook(file_ror, data_only=True)\n",
    "ror_ws = ror_wb.active\n",
    "\n",
    "# Load Power_Storage.xlsx to extract valid storage nodes\n",
    "storage_wb = load_workbook(file_storage, data_only=True)\n",
    "storage_ws = storage_wb.active\n",
    "\n",
    "valid_inflows = set() # Set to store valid inflow node IDs\n",
    "\n",
    "# Extract valid nodes from Power_RoR and Power_Storage workbooks\n",
    "for row in ror_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_inflows.add(str(row[0])) # Add valid inflows to the set\n",
    "\n",
    "for row in storage_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_inflows.add(str(row[0])) # Add valid storage nodes to the set\n",
    "\n",
    "# Load Power_Inflows.xlsx to filter rows based on valid inflow nodes\n",
    "inflows_wb = load_workbook(file_inflows) # Load the Power Inflows workbook\n",
    "inflows_ws = inflows_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing inflow nodes\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(inflows_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_inflows: # Check if the inflow node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add invalid rows to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion of the row\n",
    "\n",
    "# Delete rows in reverse order to prevent shifting issues during deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    inflows_ws.delete_rows(row_idx) # Delete the invalid rows\n",
    "\n",
    "# Save and close the filtered Power_Inflows.xlsx with updated data\n",
    "inflows_wb.save(file_inflows)\n",
    "inflows_wb.close()\n",
    "\n",
    "print(\"Power Inflows data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7 Power_NTC\n",
    "Deletes NTCs that reference buses not found in *P*ower_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 50 with node Zon_DEKF is marked for deletion.\n",
      "Row 58 with node Zon_DZ00 is marked for deletion.\n",
      "Row 59 with node Zon_DZ00 is marked for deletion.\n",
      "Row 62 with node Zon_EG00 is marked for deletion.\n",
      "Row 63 with node Zon_EG00 is marked for deletion.\n",
      "Row 73 with node Zon_FR15 is marked for deletion.\n",
      "Row 88 with node Zon_IL00 is marked for deletion.\n",
      "Row 92 with node Zon_ITCO is marked for deletion.\n",
      "Row 107 with node Zon_LY00 is marked for deletion.\n",
      "Row 118 with node Zon_PL00E is marked for deletion.\n",
      "Row 119 with node Zon_PL00E is marked for deletion.\n",
      "Row 120 with node Zon_PL00E is marked for deletion.\n",
      "Row 121 with node Zon_PL00I is marked for deletion.\n",
      "Row 133 with node Zon_MD00 is marked for deletion.\n",
      "Row 139 with node Zon_MD00 is marked for deletion.\n",
      "Row 163 with node Zon_TR00 is marked for deletion.\n",
      "Row 168 with node Zon_IL00 is marked for deletion.\n",
      "Row 170 with node Zon_PL00I is marked for deletion.\n",
      "Row 172 with node Zon_DEKF is marked for deletion.\n",
      "Row 180 with node Zon_PL00I is marked for deletion.\n",
      "Row 183 with node Zon_DKKF is marked for deletion.\n",
      "Row 184 with node Zon_DKKF is marked for deletion.\n",
      "Row 191 with node Zon_MA00 is marked for deletion.\n",
      "Row 192 with node Zon_TN00 is marked for deletion.\n",
      "Row 196 with node Zon_LY00 is marked for deletion.\n",
      "Row 198 with node Zon_MA00 is marked for deletion.\n",
      "Row 206 with node Zon_ITCO is marked for deletion.\n",
      "Row 210 with node Zon_TR00 is marked for deletion.\n",
      "Row 218 with node Zon_UA01 is marked for deletion.\n",
      "Row 221 with node Zon_PS00 is marked for deletion.\n",
      "Row 222 with node Zon_ITCO is marked for deletion.\n",
      "Row 228 with node Zon_ITVI is marked for deletion.\n",
      "Row 232 with node Zon_ITVI is marked for deletion.\n",
      "Row 234 with node Zon_ITVI is marked for deletion.\n",
      "Row 236 with node Zon_TN00 is marked for deletion.\n",
      "Row 240 with node Zon_TN00 is marked for deletion.\n",
      "Row 255 with node Zon_PL00E is marked for deletion.\n",
      "Row 258 with node Zon_UA01 is marked for deletion.\n",
      "Row 262 with node Zon_PL00I is marked for deletion.\n",
      "Row 263 with node Zon_UA01 is marked for deletion.\n",
      "Row 268 with node Zon_UA00 is marked for deletion.\n",
      "Row 269 with node Zon_UA00 is marked for deletion.\n",
      "Row 270 with node Zon_UA00 is marked for deletion.\n",
      "Row 271 with node Zon_UA00 is marked for deletion.\n",
      "Row 272 with node Zon_UA00 is marked for deletion.\n",
      "Row 30 with node Zon_TR00 is marked for deletion.\n",
      "Row 35 with node Zon_IL00 is marked for deletion.\n",
      "Row 37 with node Zon_PL00I is marked for deletion.\n",
      "Row 39 with node Zon_DEKF is marked for deletion.\n",
      "Row 47 with node Zon_PL00I is marked for deletion.\n",
      "Row 50 with node Zon_DKKF is marked for deletion.\n",
      "Row 51 with node Zon_DKKF is marked for deletion.\n",
      "Row 58 with node Zon_MA00 is marked for deletion.\n",
      "Row 59 with node Zon_TN00 is marked for deletion.\n",
      "Row 63 with node Zon_LY00 is marked for deletion.\n",
      "Row 65 with node Zon_MA00 is marked for deletion.\n",
      "Row 73 with node Zon_ITCO is marked for deletion.\n",
      "Row 77 with node Zon_TR00 is marked for deletion.\n",
      "Row 85 with node Zon_UA01 is marked for deletion.\n",
      "Row 88 with node Zon_PS00 is marked for deletion.\n",
      "Row 89 with node Zon_ITCO is marked for deletion.\n",
      "Row 95 with node Zon_ITVI is marked for deletion.\n",
      "Row 99 with node Zon_ITVI is marked for deletion.\n",
      "Row 101 with node Zon_ITVI is marked for deletion.\n",
      "Row 103 with node Zon_TN00 is marked for deletion.\n",
      "Row 107 with node Zon_TN00 is marked for deletion.\n",
      "Row 122 with node Zon_PL00E is marked for deletion.\n",
      "Row 125 with node Zon_UA01 is marked for deletion.\n",
      "Row 129 with node Zon_PL00I is marked for deletion.\n",
      "Row 130 with node Zon_UA01 is marked for deletion.\n",
      "Row 135 with node Zon_UA00 is marked for deletion.\n",
      "Row 136 with node Zon_UA00 is marked for deletion.\n",
      "Row 137 with node Zon_UA00 is marked for deletion.\n",
      "Row 138 with node Zon_UA00 is marked for deletion.\n",
      "Row 139 with node Zon_UA00 is marked for deletion.\n",
      "Row 183 with node Zon_DEKF is marked for deletion.\n",
      "Row 191 with node Zon_DZ00 is marked for deletion.\n",
      "Row 192 with node Zon_DZ00 is marked for deletion.\n",
      "Row 195 with node Zon_EG00 is marked for deletion.\n",
      "Row 196 with node Zon_EG00 is marked for deletion.\n",
      "Row 206 with node Zon_FR15 is marked for deletion.\n",
      "Row 221 with node Zon_IL00 is marked for deletion.\n",
      "Row 225 with node Zon_ITCO is marked for deletion.\n",
      "Row 240 with node Zon_LY00 is marked for deletion.\n",
      "Row 251 with node Zon_PL00E is marked for deletion.\n",
      "Row 252 with node Zon_PL00E is marked for deletion.\n",
      "Row 253 with node Zon_PL00E is marked for deletion.\n",
      "Row 254 with node Zon_PL00I is marked for deletion.\n",
      "Row 266 with node Zon_MD00 is marked for deletion.\n",
      "Row 272 with node Zon_MD00 is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power NTC data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power BusInfo and Power NTC data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_NTC = os.path.join(destination_dir, 'Power_NTC.xlsx')\n",
    "\n",
    "if is_file_open(file_NTC):\n",
    "    sys.exit(f\"File '{file_NTC}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid node IDs\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook in data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "\n",
    "# Extract valid nodes from Power_BusInfo\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0]))\n",
    "\n",
    "# Load Power_NTC.xlsx to filter rows based on valid nodes\n",
    "ntc_wb = load_workbook(file_NTC) # Load the Power NTC workbook\n",
    "ntc_ws = ntc_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing node IDs (column 2)\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(ntc_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Identify rows to delete based on invalid or missing node IDs (column 3)\n",
    "for row_idx, row in enumerate(ntc_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Remove duplicate row indices and sort in descending order to avoid shifting issues during deletion\n",
    "delete_rows = sorted(set(delete_rows))\n",
    "\n",
    "# Delete rows in reverse order to prevent issues with shifting after deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    ntc_ws.delete_rows(row_idx) # Delete the rows\n",
    "\n",
    "# Save and close the updated Power_NTC.xlsx with the filtered data\n",
    "ntc_wb.save(file_NTC)\n",
    "ntc_wb.close()\n",
    "\n",
    "print(\"Power NTC data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.8 Power_Network\n",
    "Deletes lines that reference buses not found in *P*ower_BusInfo.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 50 with node DEKF is marked for deletion.\n",
      "Row 58 with node DZ00 is marked for deletion.\n",
      "Row 59 with node DZ00 is marked for deletion.\n",
      "Row 62 with node EG00 is marked for deletion.\n",
      "Row 63 with node EG00 is marked for deletion.\n",
      "Row 73 with node FR15 is marked for deletion.\n",
      "Row 88 with node IL00 is marked for deletion.\n",
      "Row 92 with node ITCO is marked for deletion.\n",
      "Row 107 with node LY00 is marked for deletion.\n",
      "Row 118 with node PL00E is marked for deletion.\n",
      "Row 119 with node PL00E is marked for deletion.\n",
      "Row 120 with node PL00E is marked for deletion.\n",
      "Row 121 with node PL00I is marked for deletion.\n",
      "Row 133 with node MD00 is marked for deletion.\n",
      "Row 139 with node MD00 is marked for deletion.\n",
      "Row 30 with node TR00 is marked for deletion.\n",
      "Row 35 with node IL00 is marked for deletion.\n",
      "Row 37 with node PL00I is marked for deletion.\n",
      "Row 39 with node DEKF is marked for deletion.\n",
      "Row 47 with node PL00I is marked for deletion.\n",
      "Row 50 with node DKKF is marked for deletion.\n",
      "Row 51 with node DKKF is marked for deletion.\n",
      "Row 58 with node MA00 is marked for deletion.\n",
      "Row 59 with node TN00 is marked for deletion.\n",
      "Row 63 with node LY00 is marked for deletion.\n",
      "Row 65 with node MA00 is marked for deletion.\n",
      "Row 73 with node ITCO is marked for deletion.\n",
      "Row 77 with node TR00 is marked for deletion.\n",
      "Row 85 with node UA01 is marked for deletion.\n",
      "Row 88 with node PS00 is marked for deletion.\n",
      "Row 89 with node ITCO is marked for deletion.\n",
      "Row 95 with node ITVI is marked for deletion.\n",
      "Row 99 with node ITVI is marked for deletion.\n",
      "Row 101 with node ITVI is marked for deletion.\n",
      "Row 103 with node TN00 is marked for deletion.\n",
      "Row 107 with node TN00 is marked for deletion.\n",
      "Row 122 with node PL00E is marked for deletion.\n",
      "Row 125 with node UA01 is marked for deletion.\n",
      "Row 129 with node PL00I is marked for deletion.\n",
      "Row 130 with node UA01 is marked for deletion.\n",
      "Row 135 with node UA00 is marked for deletion.\n",
      "Row 136 with node UA00 is marked for deletion.\n",
      "Row 137 with node UA00 is marked for deletion.\n",
      "Row 138 with node UA00 is marked for deletion.\n",
      "Row 139 with node UA00 is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power Network data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power BusInfo and Power Network data\n",
    "file_businfo = os.path.join(destination_dir, 'Power_BusInfo.xlsx')\n",
    "file_Network = os.path.join(destination_dir, 'Power_Network.xlsx')\n",
    "\n",
    "if is_file_open(file_Network):\n",
    "    sys.exit(f\"File '{file_Network}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_BusInfo.xlsx to extract valid node IDs\n",
    "bus_wb = load_workbook(file_businfo, data_only=True) # Load workbook in data-only mode\n",
    "bus_ws = bus_wb.active\n",
    "\n",
    "valid_nodes = set() # Set to store valid node IDs\n",
    "\n",
    "# Extract valid nodes from Power_BusInfo\n",
    "for row in bus_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0])) # Add valid node IDs to the set\n",
    "\n",
    "# Load Power_Network.xlsx to filter rows based on valid nodes\n",
    "network_wb = load_workbook(file_Network) # Load the Power Network workbook\n",
    "network_ws = network_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing node IDs (column 2)\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(network_ws.iter_rows(min_row=7, min_col=2, max_col=2, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Identify rows to delete based on invalid or missing node IDs (column 3)\n",
    "for row_idx, row in enumerate(network_ws.iter_rows(min_row=7, min_col=3, max_col=3, values_only=True), start=7):\n",
    "    if row[0] is None or str(row[0]) not in valid_nodes: # Check if the node is invalid or missing\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Remove duplicate row indices and sort in descending order to avoid shifting issues during deletion\n",
    "delete_rows = sorted(set(delete_rows))\n",
    "\n",
    "# Delete rows in reverse order to prevent issues with shifting after deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    network_ws.delete_rows(row_idx) # Delete the rows\n",
    "\n",
    "# Save the updated Power_Network.xlsx with the filtered data\n",
    "network_wb.save(file_Network)\n",
    "network_wb.close()\n",
    "\n",
    "print(\"Power Network data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.9 Power_VRESProfiles\n",
    "Removes VRES profiles for VRES generators units that are not listed in *Power_VRES*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7 with node AT00 and tec CSP is marked for deletion.\n",
      "Row 8 with node BE00 and tec CSP is marked for deletion.\n",
      "Row 10 with node DZ00 and tec CSP is marked for deletion.\n",
      "Row 11 with node EG00 and tec CSP is marked for deletion.\n",
      "Row 13 with node FR00 and tec CSP is marked for deletion.\n",
      "Row 14 with node FR15 and tec CSP is marked for deletion.\n",
      "Row 15 with node GR00 and tec CSP is marked for deletion.\n",
      "Row 17 with node IL00 and tec CSP is marked for deletion.\n",
      "Row 21 with node MA00 and tec CSP is marked for deletion.\n",
      "Row 22 with node MD00 and tec CSP is marked for deletion.\n",
      "Row 23 with node PS00 and tec CSP is marked for deletion.\n",
      "Row 25 with node TR00 and tec CSP is marked for deletion.\n",
      "Row 26 with node UA00 and tec CSP is marked for deletion.\n",
      "Row 27 with node UK00 and tec CSP is marked for deletion.\n",
      "Row 46 with node DZ00 and tec Solar is marked for deletion.\n",
      "Row 48 with node EG00 and tec Solar is marked for deletion.\n",
      "Row 52 with node FR15 and tec Solar is marked for deletion.\n",
      "Row 53 with node GE00 and tec Solar is marked for deletion.\n",
      "Row 59 with node IL00 and tec Solar is marked for deletion.\n",
      "Row 61 with node LU00 and tec Solar is marked for deletion.\n",
      "Row 64 with node LY00 and tec Solar is marked for deletion.\n",
      "Row 65 with node MA00 and tec Solar is marked for deletion.\n",
      "Row 66 with node MD00 and tec Solar is marked for deletion.\n",
      "Row 67 with node ME00 and tec Solar is marked for deletion.\n",
      "Row 74 with node PS00 and tec Solar is marked for deletion.\n",
      "Row 83 with node TN00 and tec Solar is marked for deletion.\n",
      "Row 84 with node TR00 and tec Solar is marked for deletion.\n",
      "Row 85 with node UA00 and tec Solar is marked for deletion.\n",
      "Row 88 with node XK00 and tec Solar is marked for deletion.\n",
      "Row 90 with node BEIOH01 and tec Offshore is marked for deletion.\n",
      "Row 92 with node BEOH001 and tec Offshore is marked for deletion.\n",
      "Row 94 with node DE011 and tec Offshore is marked for deletion.\n",
      "Row 95 with node DE012 and tec Offshore is marked for deletion.\n",
      "Row 96 with node DE013 and tec Offshore is marked for deletion.\n",
      "Row 97 with node DE02 and tec Offshore is marked for deletion.\n",
      "Row 98 with node DEOH001 and tec Offshore is marked for deletion.\n",
      "Row 99 with node DEOH002 and tec Offshore is marked for deletion.\n",
      "Row 100 with node DEOR001 and tec Offshore is marked for deletion.\n",
      "Row 103 with node DKEOR01 and tec Offshore is marked for deletion.\n",
      "Row 104 with node DKKF and tec Offshore is marked for deletion.\n",
      "Row 105 with node DKW11 and tec Offshore is marked for deletion.\n",
      "Row 106 with node DKW12 and tec Offshore is marked for deletion.\n",
      "Row 108 with node DKWOH01 and tec Offshore is marked for deletion.\n",
      "Row 109 with node DKWOR01 and tec Offshore is marked for deletion.\n",
      "Row 110 with node EE00 and tec Offshore is marked for deletion.\n",
      "Row 111 with node EEOH001 and tec Offshore is marked for deletion.\n",
      "Row 113 with node ESOH001 and tec Offshore is marked for deletion.\n",
      "Row 114 with node ESOH002 and tec Offshore is marked for deletion.\n",
      "Row 115 with node ESOH003 and tec Offshore is marked for deletion.\n",
      "Row 117 with node FI02 and tec Offshore is marked for deletion.\n",
      "Row 118 with node FIOH001 and tec Offshore is marked for deletion.\n",
      "Row 120 with node FR02 and tec Offshore is marked for deletion.\n",
      "Row 121 with node FR03 and tec Offshore is marked for deletion.\n",
      "Row 122 with node FR04 and tec Offshore is marked for deletion.\n",
      "Row 123 with node FR08 and tec Offshore is marked for deletion.\n",
      "Row 124 with node FR09 and tec Offshore is marked for deletion.\n",
      "Row 125 with node FR13 and tec Offshore is marked for deletion.\n",
      "Row 126 with node FROH001 and tec Offshore is marked for deletion.\n",
      "Row 127 with node FROH002 and tec Offshore is marked for deletion.\n",
      "Row 128 with node FROH003 and tec Offshore is marked for deletion.\n",
      "Row 130 with node GR03 and tec Offshore is marked for deletion.\n",
      "Row 131 with node GROR001 and tec Offshore is marked for deletion.\n",
      "Row 133 with node HR01 and tec Offshore is marked for deletion.\n",
      "Row 135 with node IEOH001 and tec Offshore is marked for deletion.\n",
      "Row 136 with node ITCAOR1 and tec Offshore is marked for deletion.\n",
      "Row 137 with node ITCA and tec Offshore is marked for deletion.\n",
      "Row 138 with node ITCNOR1 and tec Offshore is marked for deletion.\n",
      "Row 140 with node ITCSOR1 and tec Offshore is marked for deletion.\n",
      "Row 142 with node ITN1OR1 and tec Offshore is marked for deletion.\n",
      "Row 144 with node ITS1OR1 and tec Offshore is marked for deletion.\n",
      "Row 146 with node ITSAOR1 and tec Offshore is marked for deletion.\n",
      "Row 148 with node ITSIOR1 and tec Offshore is marked for deletion.\n",
      "Row 151 with node LTOR001 and tec Offshore is marked for deletion.\n",
      "Row 153 with node LVOH001 and tec Offshore is marked for deletion.\n",
      "Row 155 with node NL011 and tec Offshore is marked for deletion.\n",
      "Row 156 with node NL012 and tec Offshore is marked for deletion.\n",
      "Row 157 with node NL031 and tec Offshore is marked for deletion.\n",
      "Row 158 with node NL032 and tec Offshore is marked for deletion.\n",
      "Row 159 with node NL033 and tec Offshore is marked for deletion.\n",
      "Row 161 with node NLOH001 and tec Offshore is marked for deletion.\n",
      "Row 162 with node NLOR001 and tec Offshore is marked for deletion.\n",
      "Row 163 with node NOM1 and tec Offshore is marked for deletion.\n",
      "Row 164 with node NOMOH01 and tec Offshore is marked for deletion.\n",
      "Row 165 with node NON1 and tec Offshore is marked for deletion.\n",
      "Row 166 with node NONOH01 and tec Offshore is marked for deletion.\n",
      "Row 168 with node NOSOH01 and tec Offshore is marked for deletion.\n",
      "Row 169 with node NOSOH02 and tec Offshore is marked for deletion.\n",
      "Row 170 with node NOSOR01 and tec Offshore is marked for deletion.\n",
      "Row 172 with node PLOH001 and tec Offshore is marked for deletion.\n",
      "Row 174 with node PTOH001 and tec Offshore is marked for deletion.\n",
      "Row 176 with node ROOR001 and tec Offshore is marked for deletion.\n",
      "Row 177 with node SE01 and tec Offshore is marked for deletion.\n",
      "Row 178 with node SE02 and tec Offshore is marked for deletion.\n",
      "Row 179 with node SE03 and tec Offshore is marked for deletion.\n",
      "Row 181 with node SEOH001 and tec Offshore is marked for deletion.\n",
      "Row 182 with node SEOH002 and tec Offshore is marked for deletion.\n",
      "Row 183 with node SEOH003 and tec Offshore is marked for deletion.\n",
      "Row 184 with node SEOR001 and tec Offshore is marked for deletion.\n",
      "Row 186 with node UKNIOR1 and tec Offshore is marked for deletion.\n",
      "Row 188 with node UKOH003 and tec Offshore is marked for deletion.\n",
      "Row 189 with node UKOH004 and tec Offshore is marked for deletion.\n",
      "Row 190 with node UKOH005 and tec Offshore is marked for deletion.\n",
      "Row 191 with node UKOH006 and tec Offshore is marked for deletion.\n",
      "Row 192 with node UKOR001 and tec Offshore is marked for deletion.\n",
      "Row 204 with node DZ00 and tec Wind is marked for deletion.\n",
      "Row 206 with node EG00 and tec Wind is marked for deletion.\n",
      "Row 210 with node FR15 and tec Wind is marked for deletion.\n",
      "Row 211 with node GE00 and tec Wind is marked for deletion.\n",
      "Row 217 with node IL00 and tec Wind is marked for deletion.\n",
      "Row 226 with node LU00 and tec Wind is marked for deletion.\n",
      "Row 229 with node LY00 and tec Wind is marked for deletion.\n",
      "Row 230 with node MA00 and tec Wind is marked for deletion.\n",
      "Row 231 with node MD00 and tec Wind is marked for deletion.\n",
      "Row 239 with node PS00 and tec Wind is marked for deletion.\n",
      "Row 249 with node TN00 and tec Wind is marked for deletion.\n",
      "Row 250 with node TR00 and tec Wind is marked for deletion.\n",
      "Row 251 with node UA00 and tec Wind is marked for deletion.\n",
      "Row 254 with node XK00 and tec Wind is marked for deletion.\n",
      "Row 267 with node FR15 and tec OtherRES is marked for deletion.\n",
      "Row 295 with node TR00 and tec OtherRES is marked for deletion.\n",
      "Deleting rows (can take a while for large datasets)...\n",
      "Power VRES Profiles data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for Power VRES and Power VRES Profiles data\n",
    "file_VRES = os.path.join(destination_dir, 'Power_VRES.xlsx')\n",
    "file_VRESProfiles = os.path.join(destination_dir, 'Power_VRESProfiles.xlsx')\n",
    "\n",
    "if is_file_open(file_VRESProfiles):\n",
    "    sys.exit(f\"File '{file_VRESProfiles}' is currently open by another application.\")\n",
    "\n",
    "# Load Power_VRES.xlsx and extract valid node identifiers\n",
    "vres_wb = load_workbook(file_VRES, data_only=True) # Load workbook in data-only mode\n",
    "vres_ws = vres_wb.active\n",
    "\n",
    "valid_nodes = set()# Set to store valid combined node identifiers\n",
    "\n",
    "# Extract valid profiles by combining information from columns 3 (tec) and 4 (node)\n",
    "for row in vres_ws.iter_rows(min_row=7, min_col=3, max_col=4, values_only=True):\n",
    "    if row[0] is not None:\n",
    "        valid_nodes.add(str(row[0]+row[1])) # Combine values from columns 3 and 4 to form valid inflow identifiers\n",
    "\n",
    "# Load Power_VRESProfiles.xlsx to filter rows based on valid inflows\n",
    "vresprofiles_wb = load_workbook(file_VRESProfiles) # Load the Power VRES Profiles workbook\n",
    "vresprofiles_ws = vresprofiles_wb.active\n",
    "\n",
    "# Identify rows to delete based on invalid or missing combined identifiers (columns 3 and 4)\n",
    "delete_rows = [] # List to store rows that need to be deleted\n",
    "for row_idx, row in enumerate(vresprofiles_ws.iter_rows(min_row=7, min_col=3, max_col=4, values_only=True), start=7):\n",
    "    # Combine values from columns 3 and 4 to check for valid inflow identifiers\n",
    "    if (row[1]+row[0]) is None or str(row[1]+row[0]) not in valid_nodes:\n",
    "        delete_rows.append(row_idx) # Add row index to the delete list\n",
    "        print(f\"Row {row_idx} with node {row[0]} and tec {row[1]} is marked for deletion.\") # Log the deletion\n",
    "\n",
    "# Remove duplicate row indices and sort them in reverse order to avoid shifting issues during deletion\n",
    "delete_rows = sorted(set(delete_rows))\n",
    "\n",
    "# Delete rows in reverse order to prevent issues with shifting after deletion\n",
    "print(\"Deleting rows (can take a while for large datasets)...\")\n",
    "for row_idx in reversed(delete_rows):\n",
    "    vresprofiles_ws.delete_rows(row_idx) # Delete the rows\n",
    "\n",
    "# Save and close the updated Power_VRESProfiles.xlsx with the filtered data\n",
    "vresprofiles_wb.save(file_VRESProfiles)\n",
    "vresprofiles_wb.close()\n",
    "\n",
    "print(\"Power VRES Profiles data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Copy remaining files\n",
    "Copies all necessary remaining files required by LEGO that do not need modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: Gas_H2_Demand.xlsx\n",
      "Copied: Gas_H2_GenUnits.xlsx\n",
      "Copied: Gas_H2_Network.xlsx\n",
      "Copied: Gas_Parameters.xlsx\n",
      "Copied: Global_Parameters.xlsx\n",
      "Skipped: Power_BusInfo.xlsx (already exists)\n",
      "Skipped: Power_Demand.xlsx (already exists)\n",
      "Copied: Power_DSM.xlsx\n",
      "Copied: Power_FACTS.xlsx\n",
      "Copied: Power_Hindex.xlsx\n",
      "Copied: Power_ImpExp.xlsx\n",
      "Skipped: Power_Inflows.xlsx (already exists)\n",
      "Skipped: Power_Network.xlsx (already exists)\n",
      "Skipped: Power_NTC.xlsx (already exists)\n",
      "Skipped: Power_Parameters.xlsx (already exists)\n",
      "Skipped: Power_RoR.xlsx (already exists)\n",
      "Skipped: Power_Storage.xlsx (already exists)\n",
      "Copied: Power_Tec.xlsx\n",
      "Skipped: Power_ThermalGen.xlsx (already exists)\n",
      "Skipped: Power_VRES.xlsx (already exists)\n",
      "Skipped: Power_VRESProfiles.xlsx (already exists)\n",
      "Copied: Power_WeightsK.xlsx\n",
      "Copied: Power_WeightsRP.xlsx\n",
      "Copied: Power_Zones.xlsx\n",
      "Copied: ~$Power_Network.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define source and destination folder paths for file transfer\n",
    "source_folder = template_dir\n",
    "destination_folder = destination_dir\n",
    "\n",
    "# Loop through all files in the source folder\n",
    "for filename in os.listdir(source_folder):\n",
    "    # Define full file paths for source and destination\n",
    "    src_file = os.path.join(source_folder, filename)\n",
    "    dest_file = os.path.join(destination_folder, filename)\n",
    "\n",
    "    # Check if the source is a file (not a directory) and the destination file does not already exist\n",
    "    if os.path.isfile(src_file) and not os.path.exists(dest_file):\n",
    "        shutil.copy2(src_file, dest_file)  # Copy without overwriting\n",
    "        print(f\"Copied: {filename}\") # Log the copied file\n",
    "    else:\n",
    "        print(f\"Skipped: {filename} (already exists)\") # Log skipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
